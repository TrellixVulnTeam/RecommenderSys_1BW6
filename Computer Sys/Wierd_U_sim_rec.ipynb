{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from scipy import sparse as sm\n",
    "from sklearn.preprocessing import normalize\n",
    "import numpy as np\n",
    "import csv\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from scipy.stats import spearmanr\n",
    "from scipy.stats import pearsonr as pears\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import time\n",
    "sc = SparkContext.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_rdd = sc.textFile(\"data/train.csv\")\n",
    "icm_rdd = sc.textFile(\"data/icm_fede.csv\")\n",
    "test_rdd= sc.textFile(\"data/target_users.csv\")\n",
    "\n",
    "train_header = train_rdd.first()\n",
    "icm_header = icm_rdd.first()\n",
    "test_header= test_rdd.first()\n",
    "\n",
    "train_clean_data = train_rdd.filter(lambda x: x != train_header).map(lambda line: line.split(',')).map(lambda x: (int(x[0]), int(x[1]), float(x[2])))\n",
    "icm_clean_data = icm_rdd.filter(lambda x: x != icm_header).map(lambda line: line.split(',')).map(lambda x: (int(x[0]), int(x[1])))\n",
    "test_clean_data= test_rdd.filter(lambda x: x != test_header).map(lambda line: line.split(','))\n",
    "\n",
    "test_users=test_clean_data.map( lambda x: int(x[0])).collect()\n",
    "\n",
    "\n",
    "grouped_rates = train_clean_data.filter(lambda x: x[0] in test_users).map(lambda x: (x[0],x[1])).groupByKey().map(lambda x: (x[0], list(x[1]))).collect()\n",
    "grouped_rates_dic = dict(grouped_rates)\n",
    "\n",
    "\n",
    "item_ratings = train_clean_data.map(lambda x: (x[0], x[2])).aggregateByKey((0,0), lambda x,y: (x[0] + y, x[1] + 1),lambda x,y: (x[0] + y[0], x[1] + y[1]))\n",
    "user_ratings_mean = item_ratings.mapValues(lambda x: (x[0] / (x[1]))).collect()\n",
    "user_ratings_mean_dic=dict(user_ratings_mean)\n",
    "\n",
    "\n",
    "item_ratings_forTop = train_clean_data.map(lambda x: (x[1], x[2])).aggregateByKey((0,0), lambda x,y: (x[0] + y, x[1] + 1),lambda x,y: (x[0] + y[0], x[1] + y[1]))#.sortBy(lambda x: x[1][1], ascending=False)\n",
    "#item_ratings.take(10)\n",
    "shrinkage_factor = 5\n",
    "item_ratings_mean = item_ratings_forTop.mapValues(lambda x: (x[0] / (x[1] + shrinkage_factor))).sortBy(lambda x: x[1], ascending = False).map(lambda x: x[0]).collect()\n",
    "\n",
    "\n",
    "users = train_clean_data.map(lambda x: x[0]).collect()\n",
    "items = train_clean_data.map(lambda x: x[1]).collect()\n",
    "ratings = train_clean_data.map(lambda x: x[2]).collect()\n",
    "ratings_unbiased = train_clean_data.map(lambda x: x[2]-user_ratings_mean_dic[x[0]]).collect()\n",
    "\n",
    "items_for_features= icm_clean_data.map(lambda x:x[0]).collect()\n",
    "features = icm_clean_data.map(lambda x:x[1]).collect()\n",
    "items_for_features.append(37142)\n",
    "features.append(0)\n",
    "\n",
    "\n",
    "unos=[1]*len(items_for_features)\n",
    "\n",
    "UxI= sm.csr_matrix((ratings, (users, items)))\n",
    "UxI_unbiased= sm.csr_matrix((ratings_unbiased, (users, items)))\n",
    "IxF= sm.csr_matrix((unos, (items_for_features, features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_users,n_items=UxI.shape\n",
    "n_features=IxF.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de38551c1ed643d5a3353980e06a3413"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "IDF=[0]*n_features\n",
    "for i in tqdm(range(n_features)):\n",
    "    IDF[i]=np.log10(n_items/len(IxF.getcol(i).nonzero()[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''method 1'''\n",
    "IxF=normalize(IxF,axis=1)\n",
    "IxF_idf=IxF.multiply(IDF)\n",
    "UxF=UxI.dot(IxF_idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UxU_sim=sm.csr_matrix(cosine_similarity(UxF))\n",
    "UxU_sim.setdiag(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''method 2'''\n",
    "UxF=UxI.dot(IxF).tolil()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "UxF[UxF.nonzero()]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "UxF_idf=UxF.multiply(IDF)\n",
    "UxU_sim=UxF_idf.dot(UxF_idf.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef105476912546ac9ea9d121964f0648"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/scipy/sparse/compressed.py:774: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  SparseEfficiencyWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "top_rec=5\n",
    "threshold=8\n",
    "UxI_pred=sm.lil_matrix((n_users,n_items))\n",
    "for user in tqdm(test_users):\n",
    "    top= []\n",
    "    while len(top)<=top_rec:\n",
    "        most_sim_u=UxU_sim.getrow(user).argmax()\n",
    "        if(most_sim_u==0): break\n",
    "        best_rated=UxI.getrow(most_sim_u)\n",
    "        best_rated[0,grouped_rates_dic[user]]=0\n",
    "        best_rated_idx=best_rated.toarray()[0].argsort()[::-1]\n",
    "        for item in best_rated_idx:\n",
    "            if best_rated[0,item]>=threshold:\n",
    "                top.append(item)\n",
    "            else:\n",
    "                break\n",
    "        UxU_sim[user,most_sim_u]=-9\n",
    "        pen=0\n",
    "    for itm in top:        \n",
    "        UxI_pred[user,itm]=(top_rec-pen)\n",
    "        pen+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "UxI_pred=UxI_pred.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbe9d847003b433ba0324e4235f3403f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "f = open('submission_stranezza_2.csv', 'wt')\n",
    "writer = csv.writer(f)\n",
    "writer.writerow(('userId','RecommendedItemIds'))\n",
    "\n",
    "for user in tqdm(test_users):\n",
    "    top=[0,0,0,0,0]\n",
    "\n",
    "    user_predictions=UxI_pred.getrow(user)\n",
    "    iterator = 0\n",
    "    for i in range(5):\n",
    "        prediction = user_predictions.argmax()\n",
    "        while prediction in grouped_rates_dic[user] and prediction != 0:\n",
    "            user_predictions[0,prediction]=-9\n",
    "            prediction=user_predictions.argmax()\n",
    "        if prediction == 0:\n",
    "            prediction = item_ratings_mean[iterator]\n",
    "            while prediction in grouped_rates_dic[user] or prediction in top:\n",
    "                iterator += 1\n",
    "                prediction = item_ratings_mean[iterator]\n",
    "            iterator += 1\n",
    "        else:\n",
    "            user_predictions[0,prediction]=-9\n",
    "        top[i]=prediction    \n",
    "    writer.writerow((user, '{0} {1} {2} {3} {4}'.format(top[0], top[1], top[2], top[3], top[4])))\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
