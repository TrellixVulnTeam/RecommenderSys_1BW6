{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computer Systems 2016/17\n",
    "\n",
    "### Practice 6 - Machine learning, the easy way"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We will use the Movielens 100k dataset. We download it and uncompress the file we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "sc = pyspark.SparkContext('local[*]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from urllib.request import urlretrieve\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ml-100k.zip', <http.client.HTTPMessage at 0x7f8df4b96b00>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urlretrieve (\"http://files.grouplens.org/datasets/movielens/ml-100k.zip\", \"ml-100k.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('196', '242', '3', '881250949'),\n",
       " ('186', '302', '3', '891717742'),\n",
       " ('22', '377', '1', '878887116'),\n",
       " ('244', '51', '2', '880606923'),\n",
       " ('166', '346', '1', '886397596'),\n",
       " ('298', '474', '4', '884182806'),\n",
       " ('115', '265', '2', '881171488'),\n",
       " ('253', '465', '5', '891628467'),\n",
       " ('305', '451', '3', '886324817'),\n",
       " ('6', '86', '3', '883603013')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataFile = zipfile.ZipFile(\"ml-100k.zip\")\n",
    "\n",
    "URM_path = dataFile.extract(\"ml-100k/u.data\")\n",
    "URM = sc.textFile(URM_path)\n",
    "\n",
    "\n",
    "def rowSplit (rowString):\n",
    "    split = rowString.split(\"\\t\")\n",
    "    result = tuple(split)\n",
    "    return result\n",
    "\n",
    "\n",
    "URM_tuple = URM.map(rowSplit)\n",
    "\n",
    "URM_tuple.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collaborative filtering with Matrix Fatorization\n",
    "\n",
    "#### Available in Spark within the Alternating Least Squares module <https://spark.apache.org/docs/latest/mllib-collaborative-filtering.html>\n",
    "\n",
    "#### The implementation in spark.mllib has the following parameters:\n",
    "\n",
    "* *numBlocks* is the number of blocks used to parallelize computation (set to -1 to auto-configure).\n",
    "* **rank** is the number of latent factors in the model.\n",
    "* **iterations** is the number of iterations of ALS to run. ALS typically converges to a reasonable solution in 20 iterations or less.\n",
    "* *lambda* specifies the regularization parameter in ALS.\n",
    "* *implicitPrefs* specifies whether to use the explicit feedback ALS variant or one adapted for implicit feedback data.\n",
    "* *alpha* is a parameter applicable to the implicit feedback variant of ALS that governs the baseline confidence in preference observations.\n",
    "\n",
    "#### The number of latent factors and the number of iterations are among the most important parameters to choose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train tuples 59957, test tuples 40043\n"
     ]
    }
   ],
   "source": [
    "URM_train, URM_test = URM_tuple.randomSplit([0.6, 0.4])\n",
    "\n",
    "URM_tuple = None\n",
    "\n",
    "print(\"Train tuples {}, test tuples {}\".format(URM_train.count(), URM_test.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fist thing we transform the URM in an RDD made of Rating objects, a tuple similar to MatrixEntry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Rating(user=298, product=474, rating=4.0),\n",
       " Rating(user=305, product=451, rating=3.0),\n",
       " Rating(user=286, product=1014, rating=5.0),\n",
       " Rating(user=200, product=222, rating=5.0),\n",
       " Rating(user=210, product=40, rating=3.0),\n",
       " Rating(user=224, product=29, rating=3.0),\n",
       " Rating(user=122, product=387, rating=5.0),\n",
       " Rating(user=194, product=274, rating=2.0),\n",
       " Rating(user=291, product=1042, rating=4.0),\n",
       " Rating(user=234, product=1184, rating=2.0)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.mllib.recommendation import ALS, MatrixFactorizationModel, Rating\n",
    "\n",
    "\n",
    "URM_train_rating = URM_train.map(lambda x: Rating(int(x[0]),int(x[1]),float(x[2])))\n",
    "\n",
    "URM_train_rating.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We choose the parameters and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model took 2.77 sec\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "rank = 10\n",
    "numIterations = 10\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "model = ALS.train(URM_train_rating, rank, numIterations)\n",
    "\n",
    "print(\"Training the model took {:.2f} sec\".format(time.time()-start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Then we test the model, providing as imput a user-item tuple\n",
    "\n",
    "#### First we calculate the predictions, then we compare them with the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Rating(user=894, product=1080, rating=2.120294327931365),\n",
       " Rating(user=264, product=320, rating=2.8265741074043778),\n",
       " Rating(user=896, product=320, rating=4.257202629535986),\n",
       " Rating(user=592, product=320, rating=5.946216943460995),\n",
       " Rating(user=385, product=320, rating=3.992996427523525),\n",
       " Rating(user=3, product=320, rating=1.687231568703551),\n",
       " Rating(user=118, product=320, rating=4.82193945412069),\n",
       " Rating(user=399, product=320, rating=2.084204194666195),\n",
       " Rating(user=105, product=752, rating=0.6791759304968652),\n",
       " Rating(user=713, product=752, rating=5.043054562947763)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "URM_test_rating = URM_test.map(lambda x: Rating(int(x[0]),int(x[1]),float(x[2])))\n",
    "URM_test_user_item = URM_test.map(lambda x: (int(x[0]),int(x[1])))\n",
    "\n",
    "\n",
    "predictions = model.predictAll(URM_test_user_item)\n",
    "\n",
    "predictions.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((360, 14), (5.0, 4.840680389959639)),\n",
       " ((780, 204), (5.0, 4.99273908224472)),\n",
       " ((87, 229), (4.0, 3.7359385747912377)),\n",
       " ((18, 428), (3.0, 4.189445722828491)),\n",
       " ((621, 577), (3.0, 2.8200537886057258)),\n",
       " ((292, 1010), (4.0, 3.1676952687709914)),\n",
       " ((42, 294), (4.0, 3.2563019592193942)),\n",
       " ((63, 591), (3.0, 2.5560640140179802)),\n",
       " ((11, 663), (4.0, 4.017237344838366)),\n",
       " ((102, 546), (3.0, 2.091301735481079))]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = predictions.map(lambda r: ((r[0], r[1]), r[2]))\n",
    "\n",
    "ratesAndPreds = URM_test_rating.map(lambda r: ((r[0], r[1]), r[2])).join(predictions)\n",
    "\n",
    "ratesAndPreds.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error = 1.3857322529425993\n"
     ]
    }
   ],
   "source": [
    "MSE = ratesAndPreds.map(lambda r: (r[1][0] - r[1][1])**2).mean()\n",
    "\n",
    "print(\"Mean Squared Error = \" + str(MSE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Our task however is not rating prediction, but top-n recommendation, we need to use a different function\n",
    "#### See the source code with all available functions here <http://spark.apache.org/docs/1.6.0/api/python/_modules/pyspark/mllib/recommendation.html#MatrixFactorizationModel.recommendProducts>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Rating(user=42, product=583, rating=6.848328685822787),\n",
       " Rating(user=42, product=1419, rating=6.587761534607403),\n",
       " Rating(user=42, product=593, rating=6.521754189261017),\n",
       " Rating(user=42, product=836, rating=6.270106924046066),\n",
       " Rating(user=42, product=110, rating=6.061204362310587),\n",
       " Rating(user=42, product=41, rating=5.927926246717579),\n",
       " Rating(user=42, product=51, rating=5.8909234592431705),\n",
       " Rating(user=42, product=426, rating=5.860618436444384),\n",
       " Rating(user=42, product=960, rating=5.808374916139439),\n",
       " Rating(user=42, product=502, rating=5.772652649756662)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_id = 42\n",
    "n=10\n",
    "\n",
    "singleUserRecommendation = model.recommendProducts(user_id, n)\n",
    "\n",
    "singleUserRecommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Or alternatively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(512,\n",
       "  (Rating(user=512, product=854, rating=7.921442328067799),\n",
       "   Rating(user=512, product=362, rating=7.4006094329378165),\n",
       "   Rating(user=512, product=968, rating=7.335592667645788),\n",
       "   Rating(user=512, product=445, rating=6.785823160180624),\n",
       "   Rating(user=512, product=1142, rating=6.547363222065101),\n",
       "   Rating(user=512, product=489, rating=6.535932922087715),\n",
       "   Rating(user=512, product=906, rating=6.519270182768839),\n",
       "   Rating(user=512, product=850, rating=6.341855263486819),\n",
       "   Rating(user=512, product=962, rating=6.244956545745096),\n",
       "   Rating(user=512, product=1129, rating=6.203607403050501))),\n",
       " (704,\n",
       "  (Rating(user=704, product=1129, rating=6.145218227136462),\n",
       "   Rating(user=704, product=962, rating=5.882000715255358),\n",
       "   Rating(user=704, product=1183, rating=5.837725671860948),\n",
       "   Rating(user=704, product=694, rating=5.638271935084615),\n",
       "   Rating(user=704, product=1126, rating=5.610090218137842),\n",
       "   Rating(user=704, product=320, rating=5.530093281430237),\n",
       "   Rating(user=704, product=921, rating=5.465293987901239),\n",
       "   Rating(user=704, product=1268, rating=5.4150337465557765),\n",
       "   Rating(user=704, product=1242, rating=5.38545630016087),\n",
       "   Rating(user=704, product=221, rating=5.2853059267908185))),\n",
       " (320,\n",
       "  (Rating(user=320, product=253, rating=7.4625574143349365),\n",
       "   Rating(user=320, product=1159, rating=6.273866937499522),\n",
       "   Rating(user=320, product=854, rating=6.172399441800083),\n",
       "   Rating(user=320, product=906, rating=6.064653749591865),\n",
       "   Rating(user=320, product=1142, rating=6.041936984635701),\n",
       "   Rating(user=320, product=958, rating=5.738140168065151),\n",
       "   Rating(user=320, product=1401, rating=5.705277508692083),\n",
       "   Rating(user=320, product=57, rating=5.6928053547323785),\n",
       "   Rating(user=320, product=904, rating=5.639150894758404),\n",
       "   Rating(user=320, product=421, rating=5.576448614073605)))]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allRecommendation = model.recommendProductsForUsers(n)\n",
    "\n",
    "allRecommendation.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now we compute our MAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def MAP(RankedList, PositiveItems, at=None):\n",
    "    \"\"\"\n",
    "    Calculates MAP@__ \n",
    "    \"\"\"\n",
    "    \n",
    "    RankedList = RankedList[:at]\n",
    "    is_relevant = np.in1d(RankedList, PositiveItems, assume_unique=True)\n",
    "    \n",
    "    p_at_k = is_relevant * np.cumsum(is_relevant, dtype=np.float32) / (1 + np.arange(len(is_relevant)))\n",
    "    map_score = np.sum(p_at_k) / np.min([len(PositiveItems), len(RankedList)])\n",
    "    \n",
    "    assert 0 <= map_score <= 1, map_score\n",
    "    \n",
    "    return map_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 42 has 80 positive items, some of them are: ['403', '546', '274', '44', '1028', '625', '953', '69', '121', '506']\n",
      "User 42 has 103 seen items, some of them are: ['423', '96', '794', '588', '98', '685', '176', '195', '185', '684']\n"
     ]
    }
   ],
   "source": [
    "userPositiveItems_dict = URM_test.map(lambda x: (int(x[0]), [x[1]])).reduceByKey(lambda x,y : x + y).collectAsMap()\n",
    "userSeenItems_dict = URM_train.map(lambda x: (int(x[0]), [x[1]])).reduceByKey(lambda x,y : x + y).collectAsMap()\n",
    "\n",
    "user_id = 42\n",
    "print(\"User {} has {} positive items, some of them are: {}\".\n",
    "      format(user_id, len(userPositiveItems_dict[user_id]), userPositiveItems_dict[user_id][0:10]))\n",
    "print(\"User {} has {} seen items, some of them are: {}\".\n",
    "      format(user_id, len(userSeenItems_dict[user_id]), userSeenItems_dict[user_id][0:10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's build a wrapper function that deals with the data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def recommendWithALS(model, user_id, n):\n",
    "    \n",
    "    singleUserRecommendation = model.recommendProducts(user_id, n)\n",
    "    itemsToRecommend = []\n",
    "    \n",
    "    for ratingTuple in singleUserRecommendation:\n",
    "        itemsToRecommend.append(ratingTuple.product)\n",
    "        \n",
    "    return itemsToRecommend\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[583, 1419, 593, 836, 110, 41, 51, 426, 960, 502]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_id = 42\n",
    "\n",
    "recommendWithALS(model, user_id, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAP(recommendWithALS(model, user_id, n), userPositiveItems_dict[user_id], at=n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### we have to loop through the users as ALS requires the Spark context and we cannot perform map operation using the model inside it. Here I'm computing it the slow way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculateOverallMap(model, userList, userPositiveItems_dict, at=10):\n",
    "    \n",
    "    MAP_value = 0.0\n",
    "    \n",
    "    for user_id in userList:\n",
    "        \n",
    "        MAP_value += MAP(recommendWithALS(model, user_id, at), userPositiveItems_dict[user_id], at=at)\n",
    "\n",
    "    MAP_value = MAP_value/len(userList)\n",
    "    \n",
    "    return MAP_value\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.5/site-packages/numpy/lib/arraysetops.py:395: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP value is 0.0048. Processing required 23.05 seconds\n"
     ]
    }
   ],
   "source": [
    "userList_test = URM_test.map(lambda x: int(x[0])).distinct().collect()\n",
    "userList_train = URM_train.map(lambda x: int(x[0])).distinct().collect()\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "testMAP = calculateOverallMap(model, userList_test, userPositiveItems_dict)\n",
    "\n",
    "print(\"MAP value is {:.4f}. Processing required {:.2f} seconds\".format(\\\n",
    "    testMAP, time.time()-start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What happens if we change the parameters? Let's try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.5/site-packages/numpy/lib/arraysetops.py:395: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 10, Iterations 10 - testMAP 0.0049, trainMAP 0.0033, training time 1.13 sec\n",
      "Rank 20, Iterations 10 - testMAP 0.0204, trainMAP 0.0084, training time 1.09 sec\n",
      "Rank 30, Iterations 10 - testMAP 0.0348, trainMAP 0.0177, training time 1.25 sec\n",
      "Rank 40, Iterations 10 - testMAP 0.0460, trainMAP 0.0367, training time 1.25 sec\n",
      "Rank 50, Iterations 10 - testMAP 0.0478, trainMAP 0.0787, training time 1.37 sec\n",
      "Rank 60, Iterations 10 - testMAP 0.0444, trainMAP 0.1444, training time 1.62 sec\n",
      "Rank 80, Iterations 10 - testMAP 0.0333, trainMAP 0.3011, training time 2.61 sec\n",
      "Rank 100, Iterations 10 - testMAP 0.0248, trainMAP 0.3921, training time 2.90 sec\n",
      "Rank 120, Iterations 10 - testMAP 0.0206, trainMAP 0.4537, training time 5.22 sec\n",
      "Rank 150, Iterations 10 - testMAP 0.0182, trainMAP 0.4839, training time 7.39 sec\n",
      "Rank 250, Iterations 10 - testMAP 0.0185, trainMAP 0.5017, training time 20.63 sec\n",
      "Rank 350, Iterations 10 - testMAP 0.0175, trainMAP 0.5041, training time 48.25 sec\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "rankList = [10, 20, 30, 40, 50, 60, 80, 100, 120, 150, 250, 350]\n",
    "#numIterations = [5, 10, 15, 20]\n",
    "numIterations = [10]\n",
    "\n",
    "test_case_list = itertools.product(rankList, numIterations)\n",
    "test_case_results = []\n",
    "\n",
    "for test_case in test_case_list:\n",
    "    \n",
    "    rank = test_case[0]\n",
    "    numIterations = test_case[1]\n",
    "    \n",
    "    start_time = time.time()   \n",
    "    model = ALS.train(URM_train_rating, rank, numIterations)\n",
    "    train_time = time.time()-start_time\n",
    "    \n",
    "    trainMAP = calculateOverallMap(model, userList_train, userSeenItems_dict)\n",
    "    testMAP = calculateOverallMap(model, userList_train, userPositiveItems_dict)\n",
    "    \n",
    "    print(\"Rank {}, Iterations {} - testMAP {:.4f}, trainMAP {:.4f}, training time {:.2f} sec\".\n",
    "          format(rank, numIterations, testMAP, trainMAP, train_time))\n",
    "    \n",
    "    test_case_results.append((rank, numIterations, testMAP, trainMAP, train_time))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEdCAYAAADjFntmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\njsFNV+TlAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8dc8f68390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as pyplot\n",
    "\n",
    "testMAP = []\n",
    "trainMAP = []\n",
    "\n",
    "## Select the result at iteration 10\n",
    "for result_set in test_case_results:\n",
    "\n",
    "    if result_set[1] == 10:\n",
    "        testMAP.append(result_set[2])\n",
    "        trainMAP.append(result_set[3])\n",
    "        \n",
    "\n",
    "x_positions = np.array(range(len(testMAP)))\n",
    "pyplot.xticks(x_positions, rankList)\n",
    "\n",
    "pyplot.plot(trainMAP, label=\"Train\")\n",
    "pyplot.plot(testMAP, label=\"Test\")\n",
    "\n",
    "pyplot.ylabel('MAP')\n",
    "pyplot.xlabel('Rank')\n",
    "\n",
    "pyplot.legend(bbox_to_anchor=(0., 1.02, 1., .102), loc=3,\n",
    "           ncol=3, mode=\"expand\", borderaxespad=0.)\n",
    "\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From the graph we can clearly see the impact of the number of latent factors.\n",
    "#### We can also see clearly that at some point the trainMAP increases sharply whereas the testMAP starts to decline, this is the point where our model starts to overfit. At rank 350 we have a very high trainMAP, which is now saturating, and a very low testMAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collaborative filtering with \"Sparse linear methods for top-n recommender systems\"\n",
    "#### Ning, Xia, and George Karypis. \"Slim: Sparse linear methods for top-n recommender systems.\" Data Mining (ICDM), 2011 IEEE 11th International Conference on. IEEE, 2011.\n",
    "#### <https://www.researchgate.net/profile/George_Karypis/publication/220765374_SLIM_Sparse_Linear_Methods_for_Top-N_Recommender_Systems/links/549ee9ac0cf257a635fe7010.pdf>\n",
    "\n",
    "#### As opposed to the ALS method we just saw, SLIM is optimized for Top-n recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "import scipy.sparse as sps\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The code below works for URM in Compressed Sparse Column Format (CSC)\n",
    "#### A CSC matrix has the following attributes that you can freely manipulate\n",
    "* indices is an array of row indices\n",
    "* data is an array of corresponding nonzero values\n",
    "* indptr is an array whose value in position i points to where the column i starts in indices and data\n",
    "\n",
    "#### Let's see an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0, 0, 0, 0],\n",
       "        [0, 5, 5, 0],\n",
       "        [0, 7, 6, 6],\n",
       "        [0, 0, 7, 0]], dtype=int64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows =    [1, 1, 2, 2, 2, 3]\n",
    "columns = [1, 2, 2, 3, 1, 2]\n",
    "data =    [5, 5, 6, 6, 7, 7]\n",
    "\n",
    "exampleCSCmatrix = sps.csc_matrix((data, (rows, columns)))\n",
    "\n",
    "exampleCSCmatrix.todense()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We now query the data structure\n",
    "\n",
    "#### We can see that\n",
    "* indices corresponds to the row list, in a different order\n",
    "* data corresponds to the data list, again in a different order\n",
    "* indptr corresponds to the columns list, formatted in a different way. The firs two 0 value means that column zero starts at the beginning of indices/data lists and column 1 does not exist (is empty). Column 2 starts at position 2 of indices/data and goes up to position 4, since at position 5 starts column 3\n",
    "\n",
    "#### Why use this format instead of a more simple coordinate format (row, col, value)? Because it is faster for column-wise operations  and the indptr occupies less space than listing the same coordinate value every time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 1, 2, 3, 2], dtype=int32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exampleCSCmatrix.indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 7, 5, 6, 7, 6], dtype=int64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exampleCSCmatrix.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 2, 5, 6], dtype=int32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exampleCSCmatrix.indptr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First we build a local sparse URM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "userList = URM_train.map(lambda x: int(x[0])).collect()\n",
    "itemList = URM_train.map(lambda x: int(x[1])).collect()\n",
    "ratingList = URM_train.map(lambda x: float(x[2])).collect()\n",
    "\n",
    "shape = (URM_train.map(lambda x: int(x[0])).max()+1,\n",
    "         URM_train.map(lambda x: int(x[1])).max()+1)\n",
    "\n",
    "URM_train_local = sps.csc_matrix((ratingList, (userList, itemList)), shape=shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's see an implmentation of slim for just one item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "itemNumber = URM_train_local.shape[1]\n",
    "\n",
    "l1_penalty=0.1\n",
    "l2_penalty=0.1\n",
    "positive_only=True\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "values, rows, cols = [], [], []\n",
    "\n",
    "colID = 4\n",
    "\n",
    "l1_ratio = l1_penalty / (l1_penalty + l2_penalty)\n",
    "\n",
    "model = ElasticNet(alpha=1.0,\n",
    "                   l1_ratio=l1_ratio,\n",
    "                   positive=positive_only,\n",
    "                   fit_intercept=False,\n",
    "                   copy_X=False)\n",
    "\n",
    "\n",
    "# get the target column\n",
    "y = URM_train_local[:, colID].toarray()\n",
    "\n",
    "# set the j-th column of URM to zero\n",
    "URM_train_local.data[URM_train_local.indptr[colID]:URM_train_local.indptr[colID + 1]] = 0.0\n",
    "\n",
    "# fit one ElasticNet model per column\n",
    "model.fit(URM_train_local, y)\n",
    "\n",
    "# self.model.coef_ contains the coefficient of the ElasticNet model\n",
    "# let's keep only the non-zero values\n",
    "nnz_idx = model.coef_ > 0.0\n",
    "\n",
    "values.extend(model.coef_[nnz_idx])\n",
    "rows.extend(np.arange(URM_train_local.shape[1])[nnz_idx])\n",
    "cols.extend(np.ones(nnz_idx.sum()) * colID)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The results are this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.025486808093474395,\n",
       " 0.018538821141981379,\n",
       " 0.0061280389444121368,\n",
       " 0.014382302531998669,\n",
       " 0.027055486522889197,\n",
       " 0.020868240590193828,\n",
       " 0.043061232501661446,\n",
       " 0.023974243080189757,\n",
       " 0.039850276352718969,\n",
       " 0.040744772635205651,\n",
       " 0.052170188891031172,\n",
       " 0.0050492444283079391]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[12, 22, 56, 79, 98, 100, 172, 195, 202, 204, 234, 238]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note, column values are not integer because of the multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now we put this code inside a function which returns a list of tuples (item, item, similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fitOneColumn(colID, URM, l1_penalty=0.1, l2_penalty=0.1, positive_only=True):\n",
    "    \n",
    "    l1_ratio = l1_penalty / (l1_penalty + l2_penalty)\n",
    "\n",
    "    model = ElasticNet(alpha=1.0,\n",
    "                       l1_ratio=l1_ratio,\n",
    "                       positive=positive_only,\n",
    "                       fit_intercept=False,\n",
    "                       copy_X=False)\n",
    "\n",
    "    # get the target column\n",
    "    y = URM[:, colID].toarray()\n",
    "\n",
    "    # set the colID column of URM to zero\n",
    "    URM.data[URM.indptr[colID]:URM.indptr[colID + 1]] = 0.0\n",
    "\n",
    "    # fit one ElasticNet model per column\n",
    "    model.fit(URM, y)\n",
    "\n",
    "    # self.model.coef_ contains the coefficient of the ElasticNet model\n",
    "    # let's keep only the non-zero values\n",
    "    nnz_idx = model.coef_ > 0.0\n",
    "\n",
    "    values = model.coef_[nnz_idx]\n",
    "    rows = np.arange(URM.shape[1])[nnz_idx]\n",
    "    cols = np.ones(nnz_idx.sum()) * colID\n",
    "\n",
    "    \n",
    "    return list(zip(rows, cols, values))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This function fits all similarity matrix. Is this an appropriate use of mapreduce? It is for the model training, but the subsequent collect are time consuming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fitSLIM(URM):\n",
    "    \n",
    "    itemNumber = URM.shape[1]\n",
    "    \n",
    "    itemList = sc.parallelize(list(range(itemNumber)))\n",
    "    \n",
    "    # fit item's factors in parallel\n",
    "    slimResult = itemList.flatMap(lambda x: fitOneColumn(x, URM))\n",
    "\n",
    "    rows = slimResult.map(lambda x: x[0]).collect()\n",
    "    cols = slimResult.map(lambda x: x[1]).collect()\n",
    "    values = slimResult.map(lambda x: x[2]).collect()   \n",
    "    \n",
    "    # generate the sparse weight matrix\n",
    "    return sps.csc_matrix((values, (rows, cols)), \n",
    "                              shape=(itemList.max()+1, itemList.max()+1),\n",
    "                              dtype=np.float32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### And we fit the model. Here I'm not performing any validation on the parameters, but it might be helpful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "similaritySLIM = fitSLIM(URM_train_local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1682x1682 sparse matrix of type '<class 'numpy.float32'>'\n",
       "\twith 2666 stored elements in Compressed Sparse Column format>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similaritySLIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
