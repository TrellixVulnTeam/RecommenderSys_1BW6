{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from scipy import sparse as sm\n",
    "from sklearn.preprocessing import normalize\n",
    "import numpy as np\n",
    "import csv\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from scipy.stats import spearmanr\n",
    "from scipy.stats import pearsonr as pears\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import time\n",
    "sc = SparkContext.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_rdd = sc.textFile(\"data/train.csv\")\n",
    "icm_rdd = sc.textFile(\"data/icm_fede.csv\")\n",
    "test_rdd= sc.textFile(\"data/target_users.csv\")\n",
    "\n",
    "train_header = train_rdd.first()\n",
    "icm_header = icm_rdd.first()\n",
    "test_header= test_rdd.first()\n",
    "\n",
    "train_clean_data = train_rdd.filter(lambda x: x != train_header).map(lambda line: line.split(',')).map(lambda x: (int(x[0]), int(x[1]), float(x[2])))\n",
    "icm_clean_data = icm_rdd.filter(lambda x: x != icm_header).map(lambda line: line.split(',')).map(lambda x: (int(x[0]), int(x[1])))\n",
    "test_clean_data= test_rdd.filter(lambda x: x != test_header).map(lambda line: line.split(','))\n",
    "\n",
    "test_users=test_clean_data.map( lambda x: int(x[0])).collect()\n",
    "\n",
    "\n",
    "grouped_rates = train_clean_data.filter(lambda x: x[0] in test_users).map(lambda x: (x[0],x[1])).groupByKey().map(lambda x: (x[0], list(x[1]))).collect()\n",
    "grouped_rates_dic = dict(grouped_rates)\n",
    "\n",
    "\n",
    "item_ratings = train_clean_data.map(lambda x: (x[0], x[2])).aggregateByKey((0,0), lambda x,y: (x[0] + y, x[1] + 1),lambda x,y: (x[0] + y[0], x[1] + y[1]))\n",
    "user_ratings_mean = item_ratings.mapValues(lambda x: (x[0] / (x[1]))).collect()\n",
    "user_ratings_mean_dic=dict(user_ratings_mean)\n",
    "\n",
    "\n",
    "item_ratings_forTop = train_clean_data.map(lambda x: (x[1], x[2])).aggregateByKey((0,0), lambda x,y: (x[0] + y, x[1] + 1),lambda x,y: (x[0] + y[0], x[1] + y[1]))#.sortBy(lambda x: x[1][1], ascending=False)\n",
    "#item_ratings.take(10)\n",
    "shrinkage_factor = 5\n",
    "item_ratings_mean = item_ratings_forTop.mapValues(lambda x: (x[0] / (x[1] + shrinkage_factor))).sortBy(lambda x: x[1], ascending = False).map(lambda x: x[0]).collect()\n",
    "\n",
    "\n",
    "users = train_clean_data.map(lambda x: x[0]).collect()\n",
    "items = train_clean_data.map(lambda x: x[1]).collect()\n",
    "ratings = train_clean_data.map(lambda x: x[2]).collect()\n",
    "ratings_unbiased = train_clean_data.map(lambda x: x[2]-user_ratings_mean_dic[x[0]]).collect()\n",
    "\n",
    "items_for_features= icm_clean_data.map(lambda x:x[0]).collect()\n",
    "features = icm_clean_data.map(lambda x:x[1]).collect()\n",
    "items_for_features.append(37142)\n",
    "features.append(0)\n",
    "\n",
    "\n",
    "unos=[1]*len(items_for_features)\n",
    "\n",
    "UxI= sm.csr_matrix((ratings, (users, items)))\n",
    "UxI_unbiased= sm.csr_matrix((ratings_unbiased, (users, items)))\n",
    "IxF= sm.csr_matrix((unos, (items_for_features, features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_users,n_items=UxI.shape\n",
    "n_features=IxF.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''content based'''\n",
    "IDF=[0]*n_features\n",
    "for i in tqdm(range(n_features)):\n",
    "    IDF[i]=np.log10(n_items/len(IxF.getcol(i).nonzero()[1]))\n",
    "IxF=normalize(IxF,axis=1)\n",
    "IxF_idf=IxF.multiply(IDF)\n",
    "UxF=UxI.dot(IxF_idf)\n",
    "UxI_pred_CB=UxF.dot(IxF.T).tolil()#la versione qui moltiplicata per IxF_idf fa 566"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''collaborative filtering item based via content'''\n",
    "#calc similarities\n",
    "IxI_sim=sm.csr_matrix(cosine_similarity(IxF_idf))\n",
    "IxI_sim.setdiag(0)\n",
    "#take knn items\n",
    "IxI_sim_knn=sm.lil_matrix((n_items,n_items))\n",
    "k=200\n",
    "for i in tqdm(range(n_items)):    \n",
    "    top_k_idx =IxI_sim.getrow(i).toarray()[0].argpartition(-k)[-k:]\n",
    "    IxI_sim_knn[i,top_k_idx]=IxI_sim[i,top_k_idx]  \n",
    "#calc predictions\n",
    "UxI_pred_CI=UxI.dot(IxI_sim_knn.T).tolil() #518"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''collaborative filtering user based via content'''\n",
    "#calc similarities\n",
    "UxU_sim=sm.csr_matrix(cosine_similarity(UxF))\n",
    "UxU_sim.setdiag(0)\n",
    "#take knn users\n",
    "UxU_sim_knn=sm.lil_matrix((n_users,n_users))\n",
    "k=30\n",
    "for i in tqdm(range(n_users)):    \n",
    "    top_k_idx =UxU_sim.getrow(i).toarray()[0].argpartition(-k)[-k:]\n",
    "    UxU_sim_knn[i,top_k_idx]=UxU_sim[i,top_k_idx]  \n",
    "#calc_predictions\n",
    "UxI_pred_CU=UxU_sim_knn.dot(UxI).tolil() #k=75->336 k=50->382 k=30->378"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del IxI_sim\n",
    "del IxI_sim_knn\n",
    "del IxF_idf\n",
    "del IxF\n",
    "del UxI_unbiased\n",
    "del UxF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove already voted\n",
    "for user in tqdm(test_users):\n",
    "    UxI_pred_CB[user,grouped_rates_dic[user]]=0\n",
    "    UxI_pred_CI[user,grouped_rates_dic[user]]=0\n",
    "    UxI_pred_CU[user,grouped_rates_dic[user]]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rescale algorithms\n",
    "for user in tqdm(test_users):    \n",
    "    row=UxI_pred_CB[user,:].toarray()[0]\n",
    "    OldMin=min(row)\n",
    "    OldMax=max(row)\n",
    "    UxI_pred_CB[user,:]=(((UxI_pred_CB[user,:] - OldMin) * (100 - 0)) / (OldMax - OldMin))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rescale algorithms\n",
    "for user in tqdm(test_users):        \n",
    "    row=UxI_pred_CU[user,:].toarray()[0]\n",
    "    OldMin=min(row)\n",
    "    OldMax=max(row)\n",
    "    UxI_pred_CU[user,:]=(((UxI_pred_CU[user,:] - OldMin) * (100 - 0)) / (OldMax - OldMin)) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rescale algorithms\n",
    "for user in tqdm(test_users):   \n",
    "    row=UxI_pred_CI[user,:].toarray()[0]\n",
    "    OldMin=min(row)\n",
    "    OldMax=max(row)\n",
    "    UxI_pred_CI[user,:]=(((UxI_pred_CI[user,:] - OldMin) * (100 - 0)) / (OldMax - OldMin)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "UxI_pred_CB=UxI_pred_CB.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "UxI_pred_CI=UxI_pred_CI.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "UxI_pred_CU=UxI_pred_CU.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "UxI_pred=UxI_pred_CB.multiply(0)+UxI_pred_CI.multiply(0)+UxI_pred_CU.multiply(1)\n",
    "#UxI_pred=UxI_pred_CU.multiply(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('submission_sum_CU30_different.csv', 'wt')\n",
    "writer = csv.writer(f)\n",
    "writer.writerow(('userId','RecommendedItemIds'))\n",
    "\n",
    "for user in tqdm(test_users):\n",
    "    top=[0,0,0,0,0]\n",
    "\n",
    "    user_predictions=UxI_pred.getrow(user)\n",
    "    iterator = 0\n",
    "    for i in range(5):\n",
    "        prediction = user_predictions.argmax()\n",
    "        while prediction in grouped_rates_dic[user] and prediction != 0:\n",
    "            user_predictions[0,prediction]=-9\n",
    "            prediction=user_predictions.argmax()\n",
    "        if prediction == 0:\n",
    "            prediction = item_ratings_mean[iterator]\n",
    "            while prediction in grouped_rates_dic[user] or prediction in top:\n",
    "                iterator += 1\n",
    "                prediction = item_ratings_mean[iterator]\n",
    "            iterator += 1\n",
    "        else:\n",
    "            user_predictions[0,prediction]=-9\n",
    "        top[i]=prediction    \n",
    "    writer.writerow((user, '{0} {1} {2} {3} {4}'.format(top[0], top[1], top[2], top[3], top[4])))\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bordaLikeAggr(rank1,rank2,rank3):\n",
    "    nrItems=UxI.shape[1]\n",
    "    result=[0]*nrItems\n",
    "    rg=150\n",
    "    for i in range(rg):\n",
    "        item1=rank1.argmax()\n",
    "        item2=rank2.argmax()        \n",
    "        item3=rank3.argmax()\n",
    "\n",
    "        if rank1[item1]>0.0:\n",
    "            result[item1]+=(0.45/(i+1))\n",
    "        rank1[item1]=-9\n",
    "\n",
    "        if rank2[item2]>0.0:\n",
    "            result[item2]+=(0.3/(i+1))\n",
    "        rank2[item2]=-9\n",
    "\n",
    "        if rank3[item3]>0.0:\n",
    "            result[item3]+=(0.25/(i+1))\n",
    "        rank3[item3]=-9\n",
    "\n",
    "    return sm.csr_matrix(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open('submission_bordalike_45-30-25_new.csv', 'wt')\n",
    "writer = csv.writer(f)\n",
    "writer.writerow(('userId','RecommendedItemIds'))\n",
    "for user in tqdm(test_users):\n",
    "    top=[0,0,0,0,0]\n",
    "\n",
    "    user_predictions=bordaLikeAggr(UxI_pred_CB.getrow(user).toarray()[0],UxI_pred_CI.getrow(user).toarray()[0],UxI_pred_CU.getrow(user).toarray()[0])\n",
    "    iterator = 0\n",
    "    for i in range(5):\n",
    "        prediction = user_predictions.argmax()\n",
    "        while prediction in grouped_rates_dic[user] and prediction != 0:\n",
    "            user_predictions[0,prediction]=-9\n",
    "            prediction=user_predictions.argmax()\n",
    "        if prediction == 0:\n",
    "            prediction = item_ratings_mean[iterator]\n",
    "            while prediction in grouped_rates_dic[user] or prediction in top:\n",
    "                iterator += 1\n",
    "                prediction = item_ratings_mean[iterator]\n",
    "            iterator += 1\n",
    "        else:\n",
    "            user_predictions[0,prediction]=-9\n",
    "        top[i]=prediction    \n",
    "    writer.writerow((user, '{0} {1} {2} {3} {4}'.format(top[0], top[1], top[2], top[3], top[4])))\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
