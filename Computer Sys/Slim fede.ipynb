{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from scipy import sparse as sm\n",
    "from sklearn.preprocessing import normalize\n",
    "import numpy as np\n",
    "import csv\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from sklearn.linear_model import ElasticNet\n",
    "import heapq\n",
    "\n",
    "sc = SparkContext.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_rdd = sc.textFile(\"data/train.csv\")\n",
    "icm_rdd = sc.textFile(\"data/icm_fede.csv\")\n",
    "test_rdd= sc.textFile(\"data/target_users.csv\")\n",
    "\n",
    "train_header = train_rdd.first()\n",
    "icm_header = icm_rdd.first()\n",
    "test_header= test_rdd.first()\n",
    "\n",
    "train_clean_data = train_rdd.filter(lambda x: x != train_header).map(lambda line: line.split(',')).map(lambda x: (int(x[0]), int(x[1]), float(x[2])))\n",
    "icm_clean_data = icm_rdd.filter(lambda x: x != icm_header).map(lambda line: line.split(',')).map(lambda x: (int(x[0]), int(x[1])))\n",
    "test_clean_data= test_rdd.filter(lambda x: x != test_header).map(lambda line: line.split(','))\n",
    "\n",
    "test_users=test_clean_data.map( lambda x: int(x[0])).collect()\n",
    "\n",
    "\n",
    "grouped_rates = train_clean_data.filter(lambda x: x[0] in test_users).map(lambda x: (x[0],x[1])).groupByKey().map(lambda x: (x[0], list(x[1]))).collect()\n",
    "grouped_rates_dic = dict(grouped_rates)\n",
    "\n",
    "\n",
    "item_ratings = train_clean_data.map(lambda x: (x[0], x[2])).aggregateByKey((0,0), lambda x,y: (x[0] + y, x[1] + 1),lambda x,y: (x[0] + y[0], x[1] + y[1]))\n",
    "user_ratings_mean = item_ratings.mapValues(lambda x: (x[0] / (x[1]))).collect()\n",
    "user_ratings_mean_dic=dict(user_ratings_mean)\n",
    "\n",
    "\n",
    "item_ratings_forTop = train_clean_data.map(lambda x: (x[1], x[2])).aggregateByKey((0,0), lambda x,y: (x[0] + y, x[1] + 1),lambda x,y: (x[0] + y[0], x[1] + y[1]))#.sortBy(lambda x: x[1][1], ascending=False)\n",
    "#item_ratings.take(10)\n",
    "shrinkage_factor = 5\n",
    "item_ratings_mean = item_ratings_forTop.mapValues(lambda x: (x[0] / (x[1] + shrinkage_factor))).sortBy(lambda x: x[1], ascending = False).map(lambda x: x[0]).collect()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "users = train_clean_data.map(lambda x: x[0]).collect()\n",
    "items = train_clean_data.map(lambda x: x[1]).collect()\n",
    "ratings = train_clean_data.map(lambda x: x[2]).collect()\n",
    "ratings_unbiased = train_clean_data.map(lambda x: x[2]-user_ratings_mean_dic[x[0]]).collect()\n",
    "\n",
    "shape = (train_clean_data.map(lambda x: int(x[0])).max()+1,\n",
    "         train_clean_data.map(lambda x: int(x[1])).max()+1)\n",
    "\n",
    "UxI = sm.csc_matrix((ratings, (users, items)), shape=shape)\n",
    "\n",
    "items_for_features= icm_clean_data.map(lambda x:x[0]).collect()\n",
    "features = icm_clean_data.map(lambda x:x[1]).collect()\n",
    "items_for_features.append(37142)\n",
    "features.append(0)\n",
    "\n",
    "unos=[1]*len(items_for_features)\n",
    "\n",
    "matrixinteractionsSparse = sm.csr_matrix((unos, (items_for_features, features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:429: DataConversionWarning: Data with input dtype int64 was converted to float64 by the normalize function.\n",
      "  warnings.warn(msg, _DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "matrixinteractionsSparseNorm = normalize(matrixinteractionsSparse, norm='l2', axis=1)\n",
    "matrixSimilarity = matrixinteractionsSparseNorm.dot(matrixinteractionsSparseNorm.T)\n",
    "matrixinteractionsSparse = matrixinteractionsSparse.T.tocsc()\n",
    "n_items = matrixinteractionsSparse.shape[1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d69f355df9414ea59ee3db50fa3c2398"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "listTopSimilar = []\n",
    "matrixSimilarity = matrixSimilarity.tocsc()\n",
    "for i in tqdm(range(n_items)):\n",
    "    minimum = min(400,matrixSimilarity[:,i].nnz)            #prendo minimo tra 100 e il numero di item simili\n",
    "    #top_k_idx = np.argpartition(matrixSimilarity[i,:], -maximum)[:maximum]\n",
    "    top_k_idx = matrixSimilarity[:, i].data.argpartition(-minimum)[-minimum:]\n",
    "    listTopSimilar.append(matrixSimilarity[:, i].indices[top_k_idx])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l1_penalty=0.1\n",
    "l2_penalty=0.1\n",
    "positive_only=True\n",
    "l1_ratio = l1_penalty / (l1_penalty + l2_penalty)\n",
    "\n",
    "model = ElasticNet(alpha=1.0,\n",
    "                       l1_ratio=l1_ratio,\n",
    "                       positive=positive_only,\n",
    "                       fit_intercept=False,\n",
    "                       copy_X=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "595ebc0382a242f38de1d1aaebafa795"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "values, rows, cols = [], [], []\n",
    "\n",
    "        # fit each item's factors sequentially (not in parallel)\n",
    "for j in tqdm(range(n_items)):\n",
    "            # get the target column\n",
    "            if(matrixinteractionsSparse[:, j].nnz > 0):\n",
    "                y = matrixinteractionsSparse[:, j].toarray().ravel()\n",
    "                #y = column_or_1d(y, warn=True)\n",
    "                # set the j-th column of X to zero\n",
    "                startptr = matrixinteractionsSparse.indptr[j]\n",
    "                endptr = matrixinteractionsSparse.indptr[j + 1]\n",
    "                bak = matrixinteractionsSparse.data[startptr: endptr].copy()\n",
    "                matrixinteractionsSparse.data[startptr: endptr] = 0.0\n",
    "                # fit one ElasticNet model per column\n",
    "                model.fit(matrixinteractionsSparse[:,listTopSimilar[j]],y)\n",
    "                #model.fit(matrixinteractionsSparse, y)\n",
    "                # self.model.coef_ contains the coefficient of the ElasticNet model\n",
    "                # let's keep only the non-zero values\n",
    "                nnz_idx = model.coef_ > 0.0\n",
    "                #values.extend(model.coef_[nnz_idx])\n",
    "                #rows.extend(np.arange(n_items)[nnz_idx])\n",
    "                #cols.extend(np.ones(nnz_idx.sum()) * j)\n",
    "                if (nnz_idx.sum() > 0):\n",
    "                    values.extend(model.coef_[nnz_idx])\n",
    "                    rows.extend(listTopSimilar[j][nnz_idx].flatten())\n",
    "                    # rows.extend(np.arange(nitems)[nnz_idx])\n",
    "                    cols.extend(np.ones(nnz_idx.sum()) * j)\n",
    "                # finally, replace the original values of the j-th column\n",
    "                matrixinteractionsSparse.data[startptr:endptr] = bak\n",
    "# generate the sparse weight matrix\n",
    "matrixSimilarity = sm.csc_matrix((values, (rows, cols)), shape=(n_items, n_items), dtype=np.float32)\n",
    "matrixinteractionsSparse = matrixinteractionsSparse.T.tocsc()\n",
    "listUser = []\n",
    "listValue = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in tqdm(test_users):\n",
    "    listSimilarity = matrixSimilarity[:,index]\n",
    "    scores = listSimilarity.T.dot(matrixinteractionsSparse)\n",
    "    print(scores.nnz)\n",
    "    #scores =  matrixinteractionsSparse[index,:].dot(matrixSimilarity)\n",
    "    scores = scores.toarray()[0]\n",
    "    scores *= np.negative((matrixinteractionsSparse[index,:]).astype(bool).toarray()[0])\n",
    "    sumTemp = np.sum((matrixinteractionsSparse[index, :]).astype(bool).toarray()[0])\n",
    "    if (sumTemp <= 2):\n",
    "        low_values_indices = scores < 0.001  # Where values are low\n",
    "        scores[low_values_indices] = 0  # All low values set to 0\n",
    "    topItems = heapq.nlargest(5, range(len(scores)), scores.take)\n",
    "    if(scores[topItems[0]]>0):\n",
    "        listUser.append(index)\n",
    "        listValue.append(str(topItems[0]) + \" \" + str(topItems[1]) + \" \" + str(topItems[2]) + \" \" + str(topItems[3]) + \" \" + str(topItems[4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "unos=[1]*len(items_for_features)\n",
    "\n",
    "UxI= sm.csr_matrix((ratings, (users, items)))\n",
    "UxI_coo = UxI.tocoo()\n",
    "IxF= sm.csr_matrix((unos, (items_for_features, features)))\n",
    "IxF_coo = IxF.tocoo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "def fitOneColumn(colID, URM, l1_penalty=0.1, l2_penalty=0.1, positive_only=True):\n",
    "    \n",
    "    l1_ratio = l1_penalty / (l1_penalty + l2_penalty)\n",
    "\n",
    "    model = ElasticNet(alpha=1.0,\n",
    "                       l1_ratio=l1_ratio,\n",
    "                       positive=positive_only,\n",
    "                       fit_intercept=False,\n",
    "                       copy_X=False)\n",
    "\n",
    "    # get the target column\n",
    "    y = URM[:, colID].toarray()\n",
    "\n",
    "    # set the colID column of URM to zero\n",
    "    URM.data[URM.indptr[colID]:URM.indptr[colID + 1]] = 0.0\n",
    "\n",
    "    # fit one ElasticNet model per column\n",
    "    model.fit(URM, y)\n",
    "\n",
    "    # self.model.coef_ contains the coefficient of the ElasticNet model\n",
    "    # let's keep only the non-zero values\n",
    "    nnz_idx = model.coef_ > 0.0\n",
    "\n",
    "    values = model.coef_[nnz_idx]\n",
    "    rows = np.arange(URM.shape[1])[nnz_idx]\n",
    "    cols = np.ones(nnz_idx.sum()) * colID\n",
    "\n",
    "    \n",
    "    return list(zip(rows, cols, values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "def fitSLIM(URM):\n",
    "    \n",
    "    itemNumber = URM.shape[1]\n",
    "    \n",
    "    itemList = sc.parallelize(list(range(itemNumber)))\n",
    "    \n",
    "    # fit item's factors in parallel\n",
    "    slimResult = itemList.flatMap(lambda x: fitOneColumn(x, URM))\n",
    "\n",
    "    rows = slimResult.map(lambda x: x[0]).collect()\n",
    "    cols = slimResult.map(lambda x: x[1]).collect()\n",
    "    values = slimResult.map(lambda x: x[2]).collect()   \n",
    "    \n",
    "    # generate the sparse weight matrix\n",
    "    return sps.csc_matrix((values, (rows, cols)), \n",
    "                              shape=(itemList.max()+1, itemList.max()+1),\n",
    "                              dtype=np.float32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def fitOneColumn(colID, URM, model):\n",
    "\n",
    "    # get the target column\n",
    "    y = URM[:, colID].toarray()\n",
    "\n",
    "    # set the colID column of URM to zero\n",
    "    URM.data[URM.indptr[colID]:URM.indptr[colID + 1]] = 0.0\n",
    "\n",
    "    # fit one ElasticNet model per column\n",
    "    model.fit(URM, y)\n",
    "\n",
    "    # self.model.coef_ contains the coefficient of the ElasticNet model\n",
    "    # let's keep only the non-zero values\n",
    "    nnz_idx = model.coef_ > 0.0\n",
    "\n",
    "    values = model.coef_[nnz_idx]\n",
    "    rows = np.arange(URM.shape[1])[nnz_idx]\n",
    "    cols = np.ones(nnz_idx.sum()) * colID\n",
    "\n",
    "    \n",
    "    return list(zip(rows, cols, values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def fitSLIM(URM):\n",
    "    \n",
    "    l1_penalty=0.1\n",
    "    l2_penalty=0.1\n",
    "    positive_only=True\n",
    "    l1_ratio = l1_penalty / (l1_penalty + l2_penalty)\n",
    "\n",
    "    model = ElasticNet(alpha=1.0,\n",
    "                       l1_ratio=l1_ratio,\n",
    "                       positive=positive_only,\n",
    "                       fit_intercept=False,\n",
    "                       copy_X=False)\n",
    "    \n",
    "    itemNumber = URM.shape[1]\n",
    "    \n",
    "    result = list()\n",
    "    \n",
    "    for item in tqdm(range(itemNumber)):        \n",
    "        result += fitOneColumn(item, URM, model)\n",
    "    # fit item's factors in parallel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "similaritySLIM = fitSLIM(UxI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample_recommendation(model, data, i_f, user_ids):\n",
    "\n",
    "\n",
    "    n_users, _ = data.shape\n",
    "    n_items, _ = i_f.shape\n",
    "    \n",
    "    f = open('submission_light_fede_150_30.csv', 'wt')\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(('userId','RecommendedItemIds'))\n",
    "\n",
    "    for user_id in tqdm(user_ids):\n",
    "        known_positives = set(data[user_id].indices)\n",
    "        scores = model.predict(user_id, np.arange(n_items), item_features=i_f)\n",
    "        top_items = np.argsort(-scores)\n",
    "        top_items = [item for item in top_items if item not in known_positives]\n",
    "       #mask = np.in1d(top_items, known_positives,invert=True)\n",
    "       #top_items = top_items[mask][:5]\n",
    "       #top=[0,0,0,0,0]\n",
    "        top=top_items[:5]\n",
    "        iterator = 0\n",
    "        for i in range(5 - len(top)):\n",
    "            prediction = item_ratings_mean[iterator]\n",
    "            while prediction in grouped_rates_dic[user] or prediction in top:\n",
    "                iterator += 1\n",
    "                prediction = item_ratings_mean[iterator]\n",
    "                iterator += 1\n",
    "            top.append(prediction)  \n",
    "        writer.writerow((user_id, '{0} {1} {2} {3} {4}'.format(top[0], top[1], top[2], top[3], top[4])))\n",
    "\n",
    "    f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
