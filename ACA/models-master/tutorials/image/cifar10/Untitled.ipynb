{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Copyright 2015 The TensorFlow Authors. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ==============================================================================\n",
    "\n",
    "\"\"\"Routine for decoding the CIFAR-10 binary file format.\"\"\"\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "\n",
    "from six.moves import xrange  # pylint: disable=redefined-builtin\n",
    "import tensorflow as tf\n",
    "\n",
    "# Process images of this size. Note that this differs from the original CIFAR\n",
    "# image size of 32 x 32. If one alters this number, then the entire model\n",
    "# architecture will change and any model would need to be retrained.\n",
    "IMAGE_SIZE = 24\n",
    "\n",
    "# Global constants describing the CIFAR-10 data set.\n",
    "NUM_CLASSES = 10\n",
    "NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN = 50000\n",
    "NUM_EXAMPLES_PER_EPOCH_FOR_EVAL = 10000\n",
    "\n",
    "\n",
    "def read_cifar10(filename_queue):\n",
    "  \"\"\"Reads and parses examples from CIFAR10 data files.\n",
    "\n",
    "  Recommendation: if you want N-way read parallelism, call this function\n",
    "  N times.  This will give you N independent Readers reading different\n",
    "  files & positions within those files, which will give better mixing of\n",
    "  examples.\n",
    "\n",
    "  Args:\n",
    "    filename_queue: A queue of strings with the filenames to read from.\n",
    "\n",
    "  Returns:\n",
    "    An object representing a single example, with the following fields:\n",
    "      height: number of rows in the result (32)\n",
    "      width: number of columns in the result (32)\n",
    "      depth: number of color channels in the result (3)\n",
    "      key: a scalar string Tensor describing the filename & record number\n",
    "        for this example.\n",
    "      label: an int32 Tensor with the label in the range 0..9.\n",
    "      uint8image: a [height, width, depth] uint8 Tensor with the image data\n",
    "  \"\"\"\n",
    "\n",
    "  class CIFAR10Record(object):\n",
    "    pass\n",
    "  result = CIFAR10Record()\n",
    "\n",
    "  # Dimensions of the images in the CIFAR-10 dataset.\n",
    "  # See http://www.cs.toronto.edu/~kriz/cifar.html for a description of the\n",
    "  # input format.\n",
    "  label_bytes = 1  # 2 for CIFAR-100\n",
    "  result.height = 32\n",
    "  result.width = 32\n",
    "  result.depth = 3\n",
    "  image_bytes = result.height * result.width * result.depth\n",
    "  # Every record consists of a label followed by the image, with a\n",
    "  # fixed number of bytes for each.\n",
    "  record_bytes = label_bytes + image_bytes\n",
    "\n",
    "  # Read a record, getting filenames from the filename_queue.  No\n",
    "  # header or footer in the CIFAR-10 format, so we leave header_bytes\n",
    "  # and footer_bytes at their default of 0.\n",
    "  reader = tf.FixedLengthRecordReader(record_bytes=record_bytes)\n",
    "  result.key, value = reader.read(filename_queue)\n",
    "\n",
    "  # Convert from a string to a vector of uint8 that is record_bytes long.\n",
    "  record_bytes = tf.decode_raw(value, tf.uint8)\n",
    "\n",
    "  # The first bytes represent the label, which we convert from uint8->int32.\n",
    "  result.label = tf.cast(\n",
    "      tf.strided_slice(record_bytes, [0], [label_bytes]), tf.int32)\n",
    "\n",
    "  # The remaining bytes after the label represent the image, which we reshape\n",
    "  # from [depth * height * width] to [depth, height, width].\n",
    "  depth_major = tf.reshape(\n",
    "      tf.strided_slice(record_bytes, [label_bytes],\n",
    "                       [label_bytes + image_bytes]),\n",
    "      [result.depth, result.height, result.width])\n",
    "  # Convert from [depth, height, width] to [height, width, depth].\n",
    "  result.uint8image = tf.transpose(depth_major, [1, 2, 0])\n",
    "\n",
    "  return result\n",
    "\n",
    "\n",
    "def _generate_image_and_label_batch(image, label, min_queue_examples,\n",
    "                                    batch_size, shuffle):\n",
    "  \"\"\"Construct a queued batch of images and labels.\n",
    "\n",
    "  Args:\n",
    "    image: 3-D Tensor of [height, width, 3] of type.float32.\n",
    "    label: 1-D Tensor of type.int32\n",
    "    min_queue_examples: int32, minimum number of samples to retain\n",
    "      in the queue that provides of batches of examples.\n",
    "    batch_size: Number of images per batch.\n",
    "    shuffle: boolean indicating whether to use a shuffling queue.\n",
    "\n",
    "  Returns:\n",
    "    images: Images. 4D tensor of [batch_size, height, width, 3] size.\n",
    "    labels: Labels. 1D tensor of [batch_size] size.\n",
    "  \"\"\"\n",
    "  # Create a queue that shuffles the examples, and then\n",
    "  # read 'batch_size' images + labels from the example queue.\n",
    "  num_preprocess_threads = 16\n",
    "  if shuffle:\n",
    "    images, label_batch = tf.train.shuffle_batch(\n",
    "        [image, label],\n",
    "        batch_size=batch_size,\n",
    "        num_threads=num_preprocess_threads,\n",
    "        capacity=min_queue_examples + 3 * batch_size,\n",
    "        min_after_dequeue=min_queue_examples)\n",
    "  else:\n",
    "    images, label_batch = tf.train.batch(\n",
    "        [image, label],\n",
    "        batch_size=batch_size,\n",
    "        num_threads=num_preprocess_threads,\n",
    "        capacity=min_queue_examples + 3 * batch_size)\n",
    "\n",
    "  # Display the training images in the visualizer.\n",
    "  tf.summary.image('images', images)\n",
    "\n",
    "  return images, tf.reshape(label_batch, [batch_size])\n",
    "\n",
    "\n",
    "def distorted_inputs(data_dir, batch_size):\n",
    "  \"\"\"Construct distorted input for CIFAR training using the Reader ops.\n",
    "\n",
    "  Args:\n",
    "    data_dir: Path to the CIFAR-10 data directory.\n",
    "    batch_size: Number of images per batch.\n",
    "\n",
    "  Returns:\n",
    "    images: Images. 4D tensor of [batch_size, IMAGE_SIZE, IMAGE_SIZE, 3] size.\n",
    "    labels: Labels. 1D tensor of [batch_size] size.\n",
    "  \"\"\"\n",
    "  filenames = [os.path.join(data_dir, 'data_batch_%d.bin' % i)\n",
    "               for i in xrange(1, 6)]\n",
    "  for f in filenames:\n",
    "    if not tf.gfile.Exists(f):\n",
    "      raise ValueError('Failed to find file: ' + f)\n",
    "\n",
    "  # Create a queue that produces the filenames to read.\n",
    "  filename_queue = tf.train.string_input_producer(filenames)\n",
    "\n",
    "  # Read examples from files in the filename queue.\n",
    "  read_input = read_cifar10(filename_queue)\n",
    "  reshaped_image = tf.cast(read_input.uint8image, tf.float32)\n",
    "\n",
    "  height = IMAGE_SIZE\n",
    "  width = IMAGE_SIZE\n",
    "\n",
    "  # Image processing for training the network. Note the many random\n",
    "  # distortions applied to the image.\n",
    "\n",
    "  # Randomly crop a [height, width] section of the image.\n",
    "  distorted_image = tf.random_crop(reshaped_image, [height, width, 3])\n",
    "\n",
    "  # Randomly flip the image horizontally.\n",
    "  distorted_image = tf.image.random_flip_left_right(distorted_image)\n",
    "\n",
    "  # Because these operations are not commutative, consider randomizing\n",
    "  # the order their operation.\n",
    "  distorted_image = tf.image.random_brightness(distorted_image,\n",
    "                                               max_delta=63)\n",
    "  distorted_image = tf.image.random_contrast(distorted_image,\n",
    "                                             lower=0.2, upper=1.8)\n",
    "\n",
    "  # Subtract off the mean and divide by the variance of the pixels.\n",
    "  float_image = tf.image.per_image_standardization(distorted_image)\n",
    "\n",
    "  # Set the shapes of tensors.\n",
    "  float_image.set_shape([height, width, 3])\n",
    "  read_input.label.set_shape([1])\n",
    "\n",
    "  # Ensure that the random shuffling has good mixing properties.\n",
    "  min_fraction_of_examples_in_queue = 0.4\n",
    "  min_queue_examples = int(NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN *\n",
    "                           min_fraction_of_examples_in_queue)\n",
    "  print ('Filling queue with %d CIFAR images before starting to train. '\n",
    "         'This will take a few minutes.' % min_queue_examples)\n",
    "\n",
    "  # Generate a batch of images and labels by building up a queue of examples.\n",
    "  return _generate_image_and_label_batch(float_image, read_input.label,\n",
    "                                         min_queue_examples, batch_size,\n",
    "                                         shuffle=True)\n",
    "\n",
    "\n",
    "def inputs(eval_data, data_dir, batch_size):\n",
    "  \"\"\"Construct input for CIFAR evaluation using the Reader ops.\n",
    "\n",
    "  Args:\n",
    "    eval_data: bool, indicating if one should use the train or eval data set.\n",
    "    data_dir: Path to the CIFAR-10 data directory.\n",
    "    batch_size: Number of images per batch.\n",
    "\n",
    "  Returns:\n",
    "    images: Images. 4D tensor of [batch_size, IMAGE_SIZE, IMAGE_SIZE, 3] size.\n",
    "    labels: Labels. 1D tensor of [batch_size] size.\n",
    "  \"\"\"\n",
    "  if not eval_data:\n",
    "    filenames = [os.path.join(data_dir, 'data_batch_%d.bin' % i)\n",
    "                 for i in xrange(1, 6)]\n",
    "    num_examples_per_epoch = NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN\n",
    "  else:\n",
    "    filenames = [os.path.join(data_dir, 'test_batch.bin')]\n",
    "    num_examples_per_epoch = NUM_EXAMPLES_PER_EPOCH_FOR_EVAL\n",
    "\n",
    "  for f in filenames:\n",
    "    if not tf.gfile.Exists(f):\n",
    "      raise ValueError('Failed to find file: ' + f)\n",
    "\n",
    "  # Create a queue that produces the filenames to read.\n",
    "  filename_queue = tf.train.string_input_producer(filenames)\n",
    "\n",
    "  # Read examples from files in the filename queue.\n",
    "  read_input = read_cifar10(filename_queue)\n",
    "  reshaped_image = tf.cast(read_input.uint8image, tf.float32)\n",
    "\n",
    "  height = IMAGE_SIZE\n",
    "  width = IMAGE_SIZE\n",
    "\n",
    "  # Image processing for evaluation.\n",
    "  # Crop the central [height, width] of the image.\n",
    "  resized_image = tf.image.resize_image_with_crop_or_pad(reshaped_image,\n",
    "                                                         height, width)\n",
    "\n",
    "  # Subtract off the mean and divide by the variance of the pixels.\n",
    "  float_image = tf.image.per_image_standardization(resized_image)\n",
    "\n",
    "  # Set the shapes of tensors.\n",
    "  float_image.set_shape([height, width, 3])\n",
    "  read_input.label.set_shape([1])\n",
    "\n",
    "  # Ensure that the random shuffling has good mixing properties.\n",
    "  min_fraction_of_examples_in_queue = 0.4\n",
    "  min_queue_examples = int(num_examples_per_epoch *\n",
    "                           min_fraction_of_examples_in_queue)\n",
    "\n",
    "  # Generate a batch of images and labels by building up a queue of examples.\n",
    "  return _generate_image_and_label_batch(float_image, read_input.label,\n",
    "                                         min_queue_examples, batch_size,\n",
    "                                         shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Copyright 2015 The TensorFlow Authors. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ==============================================================================\n",
    "\n",
    "\"\"\"Builds the CIFAR-10 network.\n",
    "\n",
    "Summary of available functions:\n",
    "\n",
    " # Compute input images and labels for training. If you would like to run\n",
    " # evaluations, use inputs() instead.\n",
    " inputs, labels = distorted_inputs()\n",
    "\n",
    " # Compute inference on the model inputs to make a prediction.\n",
    " predictions = inference(inputs)\n",
    "\n",
    " # Compute the total loss of the prediction with respect to the labels.\n",
    " loss = loss(predictions, labels)\n",
    "\n",
    " # Create a graph to run one step of training with respect to the loss.\n",
    " train_op = train(loss, global_step)\n",
    "\"\"\"\n",
    "# pylint: disable=missing-docstring\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import tarfile\n",
    "\n",
    "from six.moves import urllib\n",
    "import tensorflow as tf\n",
    "\n",
    "import cifar10_input\n",
    "\n",
    "FLAGS = tf.app.flags.FLAGS\n",
    "\n",
    "# Basic model parameters.\n",
    "tf.app.flags.DEFINE_integer('batch_size', 128,\n",
    "                            \"\"\"Number of images to process in a batch.\"\"\")\n",
    "tf.app.flags.DEFINE_string('data_dir', '/tmp/cifar10_data',\n",
    "                           \"\"\"Path to the CIFAR-10 data directory.\"\"\")\n",
    "tf.app.flags.DEFINE_boolean('use_fp16', False,\n",
    "                            \"\"\"Train the model using fp16.\"\"\")\n",
    "\n",
    "# Global constants describing the CIFAR-10 data set.\n",
    "IMAGE_SIZE = cifar10_input.IMAGE_SIZE\n",
    "NUM_CLASSES = cifar10_input.NUM_CLASSES\n",
    "NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN = cifar10_input.NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN\n",
    "NUM_EXAMPLES_PER_EPOCH_FOR_EVAL = cifar10_input.NUM_EXAMPLES_PER_EPOCH_FOR_EVAL\n",
    "\n",
    "\n",
    "# Constants describing the training process.\n",
    "MOVING_AVERAGE_DECAY = 0.9999     # The decay to use for the moving average.\n",
    "NUM_EPOCHS_PER_DECAY = 350.0      # Epochs after which learning rate decays.\n",
    "LEARNING_RATE_DECAY_FACTOR = 0.1  # Learning rate decay factor.\n",
    "INITIAL_LEARNING_RATE = 0.1       # Initial learning rate.\n",
    "\n",
    "# If a model is trained with multiple GPUs, prefix all Op names with tower_name\n",
    "# to differentiate the operations. Note that this prefix is removed from the\n",
    "# names of the summaries when visualizing a model.\n",
    "TOWER_NAME = 'tower'\n",
    "\n",
    "DATA_URL = 'http://www.cs.toronto.edu/~kriz/cifar-10-binary.tar.gz'\n",
    "\n",
    "\n",
    "def _activation_summary(x):\n",
    "  \"\"\"Helper to create summaries for activations.\n",
    "\n",
    "  Creates a summary that provides a histogram of activations.\n",
    "  Creates a summary that measures the sparsity of activations.\n",
    "\n",
    "  Args:\n",
    "    x: Tensor\n",
    "  Returns:\n",
    "    nothing\n",
    "  \"\"\"\n",
    "  # Remove 'tower_[0-9]/' from the name in case this is a multi-GPU training\n",
    "  # session. This helps the clarity of presentation on tensorboard.\n",
    "  tensor_name = re.sub('%s_[0-9]*/' % TOWER_NAME, '', x.op.name)\n",
    "  tf.summary.histogram(tensor_name + '/activations', x)\n",
    "  tf.summary.scalar(tensor_name + '/sparsity',\n",
    "                                       tf.nn.zero_fraction(x))\n",
    "\n",
    "\n",
    "def _variable_on_cpu(name, shape, initializer):\n",
    "  \"\"\"Helper to create a Variable stored on CPU memory.\n",
    "\n",
    "  Args:\n",
    "    name: name of the variable\n",
    "    shape: list of ints\n",
    "    initializer: initializer for Variable\n",
    "\n",
    "  Returns:\n",
    "    Variable Tensor\n",
    "  \"\"\"\n",
    "  with tf.device('/cpu:0'):\n",
    "    dtype = tf.float16 if FLAGS.use_fp16 else tf.float32\n",
    "    var = tf.get_variable(name, shape, initializer=initializer, dtype=dtype)\n",
    "  return var\n",
    "\n",
    "\n",
    "def _variable_with_weight_decay(name, shape, stddev, wd):\n",
    "  \"\"\"Helper to create an initialized Variable with weight decay.\n",
    "\n",
    "  Note that the Variable is initialized with a truncated normal distribution.\n",
    "  A weight decay is added only if one is specified.\n",
    "\n",
    "  Args:\n",
    "    name: name of the variable\n",
    "    shape: list of ints\n",
    "    stddev: standard deviation of a truncated Gaussian\n",
    "    wd: add L2Loss weight decay multiplied by this float. If None, weight\n",
    "        decay is not added for this Variable.\n",
    "\n",
    "  Returns:\n",
    "    Variable Tensor\n",
    "  \"\"\"\n",
    "  dtype = tf.float16 if FLAGS.use_fp16 else tf.float32\n",
    "  var = _variable_on_cpu(\n",
    "      name,\n",
    "      shape,\n",
    "      tf.truncated_normal_initializer(stddev=stddev, dtype=dtype))\n",
    "  if wd is not None:\n",
    "    weight_decay = tf.multiply(tf.nn.l2_loss(var), wd, name='weight_loss')\n",
    "    tf.add_to_collection('losses', weight_decay)\n",
    "  return var\n",
    "\n",
    "\n",
    "def distorted_inputs():\n",
    "  \"\"\"Construct distorted input for CIFAR training using the Reader ops.\n",
    "\n",
    "  Returns:\n",
    "    images: Images. 4D tensor of [batch_size, IMAGE_SIZE, IMAGE_SIZE, 3] size.\n",
    "    labels: Labels. 1D tensor of [batch_size] size.\n",
    "\n",
    "  Raises:\n",
    "    ValueError: If no data_dir\n",
    "  \"\"\"\n",
    "  if not FLAGS.data_dir:\n",
    "    raise ValueError('Please supply a data_dir')\n",
    "  data_dir = os.path.join(FLAGS.data_dir, 'cifar-10-batches-bin')\n",
    "  images, labels = cifar10_input.distorted_inputs(data_dir=data_dir,\n",
    "                                                  batch_size=FLAGS.batch_size)\n",
    "  if FLAGS.use_fp16:\n",
    "    images = tf.cast(images, tf.float16)\n",
    "    labels = tf.cast(labels, tf.float16)\n",
    "  return images, labels\n",
    "\n",
    "\n",
    "def inputs(eval_data):\n",
    "  \"\"\"Construct input for CIFAR evaluation using the Reader ops.\n",
    "\n",
    "  Args:\n",
    "    eval_data: bool, indicating if one should use the train or eval data set.\n",
    "\n",
    "  Returns:\n",
    "    images: Images. 4D tensor of [batch_size, IMAGE_SIZE, IMAGE_SIZE, 3] size.\n",
    "    labels: Labels. 1D tensor of [batch_size] size.\n",
    "\n",
    "  Raises:\n",
    "    ValueError: If no data_dir\n",
    "  \"\"\"\n",
    "  if not FLAGS.data_dir:\n",
    "    raise ValueError('Please supply a data_dir')\n",
    "  data_dir = os.path.join(FLAGS.data_dir, 'cifar-10-batches-bin')\n",
    "  images, labels = cifar10_input.inputs(eval_data=eval_data,\n",
    "                                        data_dir=data_dir,\n",
    "                                        batch_size=FLAGS.batch_size)\n",
    "  if FLAGS.use_fp16:\n",
    "    images = tf.cast(images, tf.float16)\n",
    "    labels = tf.cast(labels, tf.float16)\n",
    "  return images, labels\n",
    "\n",
    "\n",
    "def inference(images):\n",
    "  \"\"\"Build the CIFAR-10 model.\n",
    "\n",
    "  Args:\n",
    "    images: Images returned from distorted_inputs() or inputs().\n",
    "\n",
    "  Returns:\n",
    "    Logits.\n",
    "  \"\"\"\n",
    "  # We instantiate all variables using tf.get_variable() instead of\n",
    "  # tf.Variable() in order to share variables across multiple GPU training runs.\n",
    "  # If we only ran this model on a single GPU, we could simplify this function\n",
    "  # by replacing all instances of tf.get_variable() with tf.Variable().\n",
    "  #\n",
    "  # conv1\n",
    "  with tf.variable_scope('conv1') as scope:\n",
    "    kernel = _variable_with_weight_decay('weights',\n",
    "                                         shape=[5, 5, 3, 64],\n",
    "                                         stddev=5e-2,\n",
    "                                         wd=0.0)\n",
    "    conv = tf.nn.conv2d(images, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "    biases = _variable_on_cpu('biases', [64], tf.constant_initializer(0.0))\n",
    "    pre_activation = tf.nn.bias_add(conv, biases)\n",
    "    conv1 = tf.nn.relu(pre_activation, name=scope.name)\n",
    "    _activation_summary(conv1)\n",
    "\n",
    "  # pool1\n",
    "  pool1 = tf.nn.max_pool(conv1, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1],\n",
    "                         padding='SAME', name='pool1')\n",
    "  # norm1\n",
    "  norm1 = tf.nn.lrn(pool1, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75,\n",
    "                    name='norm1')\n",
    "\n",
    "  # conv2\n",
    "  with tf.variable_scope('conv2') as scope:\n",
    "    kernel = _variable_with_weight_decay('weights',\n",
    "                                         shape=[5, 5, 64, 64],\n",
    "                                         stddev=5e-2,\n",
    "                                         wd=0.0)\n",
    "    conv = tf.nn.conv2d(norm1, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "    biases = _variable_on_cpu('biases', [64], tf.constant_initializer(0.1))\n",
    "    pre_activation = tf.nn.bias_add(conv, biases)\n",
    "    conv2 = tf.nn.relu(pre_activation, name=scope.name)\n",
    "    _activation_summary(conv2)\n",
    "\n",
    "  # norm2\n",
    "  norm2 = tf.nn.lrn(conv2, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75,\n",
    "                    name='norm2')\n",
    "  # pool2\n",
    "  pool2 = tf.nn.max_pool(norm2, ksize=[1, 3, 3, 1],\n",
    "                         strides=[1, 2, 2, 1], padding='SAME', name='pool2')\n",
    "\n",
    "  # local3\n",
    "  with tf.variable_scope('local3') as scope:\n",
    "    # Move everything into depth so we can perform a single matrix multiply.\n",
    "    reshape = tf.reshape(pool2, [FLAGS.batch_size, -1])\n",
    "    dim = reshape.get_shape()[1].value\n",
    "    weights = _variable_with_weight_decay('weights', shape=[dim, 384],\n",
    "                                          stddev=0.04, wd=0.004)\n",
    "    biases = _variable_on_cpu('biases', [384], tf.constant_initializer(0.1))\n",
    "    local3 = tf.nn.relu(tf.matmul(reshape, weights) + biases, name=scope.name)\n",
    "    _activation_summary(local3)\n",
    "\n",
    "  # local4\n",
    "  with tf.variable_scope('local4') as scope:\n",
    "    weights = _variable_with_weight_decay('weights', shape=[384, 192],\n",
    "                                          stddev=0.04, wd=0.004)\n",
    "    biases = _variable_on_cpu('biases', [192], tf.constant_initializer(0.1))\n",
    "    local4 = tf.nn.relu(tf.matmul(local3, weights) + biases, name=scope.name)\n",
    "    _activation_summary(local4)\n",
    "\n",
    "  # linear layer(WX + b),\n",
    "  # We don't apply softmax here because\n",
    "  # tf.nn.sparse_softmax_cross_entropy_with_logits accepts the unscaled logits\n",
    "  # and performs the softmax internally for efficiency.\n",
    "  with tf.variable_scope('softmax_linear') as scope:\n",
    "    weights = _variable_with_weight_decay('weights', [192, NUM_CLASSES],\n",
    "                                          stddev=1/192.0, wd=0.0)\n",
    "    biases = _variable_on_cpu('biases', [NUM_CLASSES],\n",
    "                              tf.constant_initializer(0.0))\n",
    "    softmax_linear = tf.add(tf.matmul(local4, weights), biases, name=scope.name)\n",
    "    _activation_summary(softmax_linear)\n",
    "\n",
    "  return softmax_linear\n",
    "\n",
    "\n",
    "def loss(logits, labels):\n",
    "  \"\"\"Add L2Loss to all the trainable variables.\n",
    "\n",
    "  Add summary for \"Loss\" and \"Loss/avg\".\n",
    "  Args:\n",
    "    logits: Logits from inference().\n",
    "    labels: Labels from distorted_inputs or inputs(). 1-D tensor\n",
    "            of shape [batch_size]\n",
    "\n",
    "  Returns:\n",
    "    Loss tensor of type float.\n",
    "  \"\"\"\n",
    "  # Calculate the average cross entropy loss across the batch.\n",
    "  labels = tf.cast(labels, tf.int64)\n",
    "  cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "      labels=labels, logits=logits, name='cross_entropy_per_example')\n",
    "  cross_entropy_mean = tf.reduce_mean(cross_entropy, name='cross_entropy')\n",
    "  tf.add_to_collection('losses', cross_entropy_mean)\n",
    "\n",
    "  # The total loss is defined as the cross entropy loss plus all of the weight\n",
    "  # decay terms (L2 loss).\n",
    "  return tf.add_n(tf.get_collection('losses'), name='total_loss')\n",
    "\n",
    "\n",
    "def _add_loss_summaries(total_loss):\n",
    "  \"\"\"Add summaries for losses in CIFAR-10 model.\n",
    "\n",
    "  Generates moving average for all losses and associated summaries for\n",
    "  visualizing the performance of the network.\n",
    "\n",
    "  Args:\n",
    "    total_loss: Total loss from loss().\n",
    "  Returns:\n",
    "    loss_averages_op: op for generating moving averages of losses.\n",
    "  \"\"\"\n",
    "  # Compute the moving average of all individual losses and the total loss.\n",
    "  loss_averages = tf.train.ExponentialMovingAverage(0.9, name='avg')\n",
    "  losses = tf.get_collection('losses')\n",
    "  loss_averages_op = loss_averages.apply(losses + [total_loss])\n",
    "\n",
    "  # Attach a scalar summary to all individual losses and the total loss; do the\n",
    "  # same for the averaged version of the losses.\n",
    "  for l in losses + [total_loss]:\n",
    "    # Name each loss as '(raw)' and name the moving average version of the loss\n",
    "    # as the original loss name.\n",
    "    tf.summary.scalar(l.op.name + ' (raw)', l)\n",
    "    tf.summary.scalar(l.op.name, loss_averages.average(l))\n",
    "\n",
    "  return loss_averages_op\n",
    "\n",
    "\n",
    "def train(total_loss, global_step):\n",
    "  \"\"\"Train CIFAR-10 model.\n",
    "\n",
    "  Create an optimizer and apply to all trainable variables. Add moving\n",
    "  average for all trainable variables.\n",
    "\n",
    "  Args:\n",
    "    total_loss: Total loss from loss().\n",
    "    global_step: Integer Variable counting the number of training steps\n",
    "      processed.\n",
    "  Returns:\n",
    "    train_op: op for training.\n",
    "  \"\"\"\n",
    "  # Variables that affect learning rate.\n",
    "  num_batches_per_epoch = NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN / FLAGS.batch_size\n",
    "  decay_steps = int(num_batches_per_epoch * NUM_EPOCHS_PER_DECAY)\n",
    "\n",
    "  # Decay the learning rate exponentially based on the number of steps.\n",
    "  lr = tf.train.exponential_decay(INITIAL_LEARNING_RATE,\n",
    "                                  global_step,\n",
    "                                  decay_steps,\n",
    "                                  LEARNING_RATE_DECAY_FACTOR,\n",
    "                                  staircase=True)\n",
    "  tf.summary.scalar('learning_rate', lr)\n",
    "\n",
    "  # Generate moving averages of all losses and associated summaries.\n",
    "  loss_averages_op = _add_loss_summaries(total_loss)\n",
    "\n",
    "  # Compute gradients.\n",
    "  with tf.control_dependencies([loss_averages_op]):\n",
    "    opt = tf.train.GradientDescentOptimizer(lr)\n",
    "    grads = opt.compute_gradients(total_loss)\n",
    "\n",
    "  # Apply gradients.\n",
    "  apply_gradient_op = opt.apply_gradients(grads, global_step=global_step)\n",
    "\n",
    "  # Add histograms for trainable variables.\n",
    "  for var in tf.trainable_variables():\n",
    "    tf.summary.histogram(var.op.name, var)\n",
    "\n",
    "  # Add histograms for gradients.\n",
    "  for grad, var in grads:\n",
    "    if grad is not None:\n",
    "      tf.summary.histogram(var.op.name + '/gradients', grad)\n",
    "\n",
    "  # Track the moving averages of all trainable variables.\n",
    "  variable_averages = tf.train.ExponentialMovingAverage(\n",
    "      MOVING_AVERAGE_DECAY, global_step)\n",
    "  variables_averages_op = variable_averages.apply(tf.trainable_variables())\n",
    "\n",
    "  with tf.control_dependencies([apply_gradient_op, variables_averages_op]):\n",
    "    train_op = tf.no_op(name='train')\n",
    "\n",
    "  return train_op\n",
    "\n",
    "\n",
    "def maybe_download_and_extract():\n",
    "  \"\"\"Download and extract the tarball from Alex's website.\"\"\"\n",
    "  dest_directory = FLAGS.data_dir\n",
    "  if not os.path.exists(dest_directory):\n",
    "    os.makedirs(dest_directory)\n",
    "  filename = DATA_URL.split('/')[-1]\n",
    "  filepath = os.path.join(dest_directory, filename)\n",
    "  if not os.path.exists(filepath):\n",
    "    def _progress(count, block_size, total_size):\n",
    "      sys.stdout.write('\\r>> Downloading %s %.1f%%' % (filename,\n",
    "          float(count * block_size) / float(total_size) * 100.0))\n",
    "      sys.stdout.flush()\n",
    "    filepath, _ = urllib.request.urlretrieve(DATA_URL, filepath, _progress)\n",
    "    print()\n",
    "    statinfo = os.stat(filepath)\n",
    "    print('Successfully downloaded', filename, statinfo.st_size, 'bytes.')\n",
    "  extracted_dir_path = os.path.join(dest_directory, 'cifar-10-batches-bin')\n",
    "  if not os.path.exists(extracted_dir_path):\n",
    "    tarfile.open(filepath, 'r:gz').extractall(dest_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ArgumentError",
     "evalue": "argument --batch_size: conflicting option string: --batch_size",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mArgumentError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-0f5ee20b287d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mcifar10\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[0mFLAGS\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFLAGS\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Urzi\\Desktop\\ACA\\models-master\\tutorials\\image\\cifar10\\cifar10.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;31m# Basic model parameters.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m tf.app.flags.DEFINE_integer('batch_size', 128,\n\u001b[1;32m---> 52\u001b[1;33m                             \"\"\"Number of images to process in a batch.\"\"\")\n\u001b[0m\u001b[0;32m     53\u001b[0m tf.app.flags.DEFINE_string('data_dir', '/tmp/cifar10_data',\n\u001b[0;32m     54\u001b[0m                            \"\"\"Path to the CIFAR-10 data directory.\"\"\")\n",
      "\u001b[1;32mC:\\Users\\Urzi\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\platform\\flags.py\u001b[0m in \u001b[0;36mDEFINE_integer\u001b[1;34m(flag_name, default_value, docstring)\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[0mdocstring\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mA\u001b[0m \u001b[0mhelpful\u001b[0m \u001b[0mmessage\u001b[0m \u001b[0mexplaining\u001b[0m \u001b[0mthe\u001b[0m \u001b[0muse\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mflag\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m   \"\"\"\n\u001b[1;32m---> 91\u001b[1;33m   \u001b[0m_define_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mflag_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdocstring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Urzi\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\platform\\flags.py\u001b[0m in \u001b[0;36m_define_helper\u001b[1;34m(flag_name, default_value, docstring, flagtype)\u001b[0m\n\u001b[0;32m     63\u001b[0m                               \u001b[0mdefault\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdefault_value\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m                               \u001b[0mhelp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdocstring\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m                               type=flagtype)\n\u001b[0m\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Urzi\\Anaconda3\\envs\\tensorflow\\lib\\argparse.py\u001b[0m in \u001b[0;36madd_argument\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1342\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"length of metavar tuple does not match nargs\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1343\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1344\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_add_action\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1345\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1346\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0madd_argument_group\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Urzi\\Anaconda3\\envs\\tensorflow\\lib\\argparse.py\u001b[0m in \u001b[0;36m_add_action\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m   1705\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_add_action\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1706\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moption_strings\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1707\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_optionals\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_add_action\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1708\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1709\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_positionals\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_add_action\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Urzi\\Anaconda3\\envs\\tensorflow\\lib\\argparse.py\u001b[0m in \u001b[0;36m_add_action\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m   1546\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1547\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_add_action\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1548\u001b[1;33m         \u001b[0maction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_ArgumentGroup\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_add_action\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1549\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_group_actions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1550\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Urzi\\Anaconda3\\envs\\tensorflow\\lib\\argparse.py\u001b[0m in \u001b[0;36m_add_action\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m   1356\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_add_action\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1357\u001b[0m         \u001b[1;31m# resolve any conflicts\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1358\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_conflict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1359\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1360\u001b[0m         \u001b[1;31m# add to actions list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Urzi\\Anaconda3\\envs\\tensorflow\\lib\\argparse.py\u001b[0m in \u001b[0;36m_check_conflict\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m   1495\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mconfl_optionals\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1496\u001b[0m             \u001b[0mconflict_handler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_handler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1497\u001b[1;33m             \u001b[0mconflict_handler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfl_optionals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1498\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1499\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_handle_conflict_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconflicting_actions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Urzi\\Anaconda3\\envs\\tensorflow\\lib\\argparse.py\u001b[0m in \u001b[0;36m_handle_conflict_error\u001b[1;34m(self, action, conflicting_actions)\u001b[0m\n\u001b[0;32m   1504\u001b[0m                                      \u001b[1;32mfor\u001b[0m \u001b[0moption_string\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1505\u001b[0m                                      in conflicting_actions])\n\u001b[1;32m-> 1506\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mArgumentError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mconflict_string\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1507\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1508\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_handle_conflict_resolve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconflicting_actions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mArgumentError\u001b[0m: argument --batch_size: conflicting option string: --batch_size"
     ]
    }
   ],
   "source": [
    "# Copyright 2015 The TensorFlow Authors. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ==============================================================================\n",
    "\n",
    "\"\"\"A binary to train CIFAR-10 using a single GPU.\n",
    "\n",
    "Accuracy:\n",
    "cifar10_train.py achieves ~86% accuracy after 100K steps (256 epochs of\n",
    "data) as judged by cifar10_eval.py.\n",
    "\n",
    "Speed: With batch_size 128.\n",
    "\n",
    "System        | Step Time (sec/batch)  |     Accuracy\n",
    "------------------------------------------------------------------\n",
    "1 Tesla K20m  | 0.35-0.60              | ~86% at 60K steps  (5 hours)\n",
    "1 Tesla K40m  | 0.25-0.35              | ~86% at 100K steps (4 hours)\n",
    "\n",
    "Usage:\n",
    "Please see the tutorial and website for how to download the CIFAR-10\n",
    "data set, compile the program and train the model.\n",
    "\n",
    "http://tensorflow.org/tutorials/deep_cnn/\n",
    "\"\"\"\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import cifar10\n",
    "\n",
    "FLAGS = tf.app.flags.FLAGS\n",
    "\n",
    "tf.app.flags.DEFINE_string('train_dir', '/tmp/cifar10_train',\n",
    "                           \"\"\"Directory where to write event logs \"\"\"\n",
    "                           \"\"\"and checkpoint.\"\"\")\n",
    "tf.app.flags.DEFINE_integer('max_steps', 1000000,\n",
    "                            \"\"\"Number of batches to run.\"\"\")\n",
    "tf.app.flags.DEFINE_boolean('log_device_placement', False,\n",
    "                            \"\"\"Whether to log device placement.\"\"\")\n",
    "tf.app.flags.DEFINE_integer('log_frequency', 10,\n",
    "                            \"\"\"How often to log results to the console.\"\"\")\n",
    "\n",
    "\n",
    "def train():\n",
    "  \"\"\"Train CIFAR-10 for a number of steps.\"\"\"\n",
    "  with tf.Graph().as_default():\n",
    "    global_step = tf.contrib.framework.get_or_create_global_step()\n",
    "\n",
    "    # Get images and labels for CIFAR-10.\n",
    "    images, labels = cifar10.distorted_inputs()\n",
    "\n",
    "    # Build a Graph that computes the logits predictions from the\n",
    "    # inference model.\n",
    "    logits = cifar10.inference(images)\n",
    "\n",
    "    # Calculate loss.\n",
    "    loss = cifar10.loss(logits, labels)\n",
    "\n",
    "    # Build a Graph that trains the model with one batch of examples and\n",
    "    # updates the model parameters.\n",
    "    train_op = cifar10.train(loss, global_step)\n",
    "\n",
    "    class _LoggerHook(tf.train.SessionRunHook):\n",
    "      \"\"\"Logs loss and runtime.\"\"\"\n",
    "\n",
    "      def begin(self):\n",
    "        self._step = -1\n",
    "        self._start_time = time.time()\n",
    "\n",
    "      def before_run(self, run_context):\n",
    "        self._step += 1\n",
    "        return tf.train.SessionRunArgs(loss)  # Asks for loss value.\n",
    "\n",
    "      def after_run(self, run_context, run_values):\n",
    "        if self._step % FLAGS.log_frequency == 0:\n",
    "          current_time = time.time()\n",
    "          duration = current_time - self._start_time\n",
    "          self._start_time = current_time\n",
    "\n",
    "          loss_value = run_values.results\n",
    "          examples_per_sec = FLAGS.log_frequency * FLAGS.batch_size / duration\n",
    "          sec_per_batch = float(duration / FLAGS.log_frequency)\n",
    "\n",
    "          format_str = ('%s: step %d, loss = %.2f (%.1f examples/sec; %.3f '\n",
    "                        'sec/batch)')\n",
    "          print (format_str % (datetime.now(), self._step, loss_value,\n",
    "                               examples_per_sec, sec_per_batch))\n",
    "\n",
    "    with tf.train.MonitoredTrainingSession(\n",
    "        checkpoint_dir=FLAGS.train_dir,\n",
    "        hooks=[tf.train.StopAtStepHook(last_step=FLAGS.max_steps),\n",
    "               tf.train.NanTensorHook(loss),\n",
    "               _LoggerHook()],\n",
    "        config=tf.ConfigProto(\n",
    "            log_device_placement=FLAGS.log_device_placement)) as mon_sess:\n",
    "      while not mon_sess.should_stop():\n",
    "        mon_sess.run(train_op)\n",
    "\n",
    "\n",
    "def main(argv=None):  # pylint: disable=unused-argument\n",
    "  cifar10.maybe_download_and_extract()\n",
    "  if tf.gfile.Exists(FLAGS.train_dir):\n",
    "    tf.gfile.DeleteRecursively(FLAGS.train_dir)\n",
    "  tf.gfile.MakeDirs(FLAGS.train_dir)\n",
    "  train()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  tf.app.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
