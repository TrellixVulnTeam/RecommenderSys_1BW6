{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Copyright 2015 The TensorFlow Authors. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ==============================================================================\n",
    "\n",
    "\"\"\"Evaluation for CIFAR-10.\n",
    "\n",
    "Accuracy:\n",
    "cifar10_train.py achieves 83.0% accuracy after 100K steps (256 epochs\n",
    "of data) as judged by cifar10_eval.py.\n",
    "\n",
    "Speed:\n",
    "On a single Tesla K40, cifar10_train.py processes a single batch of 128 images\n",
    "in 0.25-0.35 sec (i.e. 350 - 600 images /sec). The model reaches ~86%\n",
    "accuracy after 100K steps in 8 hours of training time.\n",
    "\n",
    "Usage:\n",
    "Please see the tutorial and website for how to download the CIFAR-10\n",
    "data set, compile the program and train the model.\n",
    "\n",
    "http://tensorflow.org/tutorials/deep_cnn/\n",
    "\"\"\"\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "from datetime import datetime\n",
    "import math\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import cifar10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "FLAGS = tf.app.flags.FLAGS\n",
    "\n",
    "tf.app.flags.DEFINE_string('eval_dir', '/tmp/cifar10_eval',\n",
    "                           \"\"\"Directory where to write event logs.\"\"\")\n",
    "tf.app.flags.DEFINE_string('eval_data', 'test',\n",
    "                           \"\"\"Either 'test' or 'train_eval'.\"\"\")\n",
    "tf.app.flags.DEFINE_string('checkpoint_dir', '/tmp/cifar10_train',\n",
    "                           \"\"\"Directory where to read model checkpoints.\"\"\")\n",
    "tf.app.flags.DEFINE_integer('eval_interval_secs', 60 * 5,\n",
    "                            \"\"\"How often to run the eval.\"\"\")\n",
    "tf.app.flags.DEFINE_integer('num_examples', 10000,\n",
    "                            \"\"\"Number of examples to run.\"\"\")\n",
    "tf.app.flags.DEFINE_boolean('run_once', False,\n",
    "                         \"\"\"Whether to run eval only once.\"\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def eval_once(saver, summary_writer, top_k_op, summary_op):\n",
    "    \"\"\"Run Eval once.\n",
    "\n",
    "  Args:\n",
    "    saver: Saver.\n",
    "    summary_writer: Summary writer.\n",
    "    top_k_op: Top K op.\n",
    "    summary_op: Summary op.\n",
    "  \"\"\"\n",
    "    with tf.Session() as sess:\n",
    "        ckpt = tf.train.get_checkpoint_state(FLAGS.checkpoint_dir)\n",
    "        if ckpt and ckpt.model_checkpoint_path:\n",
    "        # Restores from checkpoint\n",
    "            saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "        # Assuming model_checkpoint_path looks something like:\n",
    "        #   /my-favorite-path/cifar10_train/model.ckpt-0,\n",
    "        # extract global_step from it.\n",
    "            global_step = ckpt.model_checkpoint_path.split('/')[-1].split('-')[-1]\n",
    "        else:\n",
    "            print('No checkpoint file found')\n",
    "            return\n",
    "\n",
    "    # Start the queue runners.\n",
    "        coord = tf.train.Coordinator()\n",
    "        try:\n",
    "            threads = []\n",
    "            for qr in tf.get_collection(tf.GraphKeys.QUEUE_RUNNERS):\n",
    "                threads.extend(qr.create_threads(sess, coord=coord, daemon=True,\n",
    "                                         start=True))\n",
    "\n",
    "            num_iter = int(math.ceil(FLAGS.num_examples / FLAGS.batch_size))\n",
    "            true_count = 0  # Counts the number of correct predictions.\n",
    "            total_sample_count = num_iter * FLAGS.batch_size\n",
    "            step = 0\n",
    "            while step < num_iter and not coord.should_stop():\n",
    "                predictions = sess.run([top_k_op])\n",
    "                true_count += np.sum(predictions)\n",
    "                step += 1\n",
    "\n",
    "        # Compute precision @ 1.\n",
    "            precision = true_count / total_sample_count\n",
    "            print('%s: precision @ 1 = %.3f' % (datetime.now(), precision))\n",
    "\n",
    "            summary = tf.Summary()\n",
    "            summary.ParseFromString(sess.run(summary_op))\n",
    "            summary.value.add(tag='Precision @ 1', simple_value=precision)\n",
    "            summary_writer.add_summary(summary, global_step)\n",
    "        except Exception as e:  # pylint: disable=broad-except\n",
    "            coord.request_stop(e)\n",
    "\n",
    "        coord.request_stop()\n",
    "        coord.join(threads, stop_grace_period_secs=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def inputs():\n",
    "    filename_queue = tf.train.string_input_producer(\n",
    "    tf.train.match_filenames_once(\"./images/6.jpg\"))\n",
    "\n",
    "    # Read an entire image file which is required since they're JPEGs, if the images\n",
    "    # are too large they could be split in advance to smaller files or use the Fixed\n",
    "    # reader to split up the file.\n",
    "    image_reader = tf.WholeFileReader()\n",
    "\n",
    "    # Read a whole file from the queue, the first returned value in the tuple is the\n",
    "    # filename which we are ignoring.\n",
    "    _,image_file = image_reader.read(filename_queue)\n",
    "\n",
    "    label = tf.Variable(6)\n",
    "    \n",
    "    # Decode the image as a JPEG file, this will turn it into a Tensor which we can\n",
    "    # then use in training.\n",
    "    image = tf.image.decode_jpeg(image_file)\n",
    "\n",
    "    # Start a new session to show example output.\n",
    "    with tf.Session() as sess:\n",
    "        # Required to get the filename matching to run.\n",
    "        init = (tf.global_variables_initializer(), tf.local_variables_initializer())\n",
    "        sess.run([init])\n",
    "\n",
    "        # Coordinate the loading of image files.\n",
    "        coord = tf.train.Coordinator()\n",
    "        threads = tf.train.start_queue_runners(coord=coord)\n",
    "\n",
    "        # Get an image tensor and print its value.\n",
    "        image_tensor = sess.run([image])\n",
    "        label_tensor = sess.run([[label]])\n",
    "        print(image_tensor)\n",
    "        print(label_tensor)\n",
    "        # Finish off the filename queue coordinator.\n",
    "        coord.request_stop()\n",
    "        coord.join(threads)\n",
    "        return image_tensor, label_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def evaluate():\n",
    "    \"\"\"Eval CIFAR-10 for a number of steps.\"\"\"\n",
    "    with tf.Graph().as_default() as g:\n",
    "    # Get images and labels for CIFAR-10.\n",
    "        eval_data = FLAGS.eval_data == 'test'\n",
    "       # images, labels = cifar10.inputs(eval_data=eval_data)\n",
    "        image, label = inputs()\n",
    "    # Build a Graph that computes the logits predictions from the\n",
    "    # inference model.\n",
    "        logits = cifar10.inference(image)\n",
    "    \n",
    "    # Calculate predictions.\n",
    "        top_k_op = tf.nn.in_top_k(logits, label, 1)\n",
    "\n",
    "    # Restore the moving average version of the learned variables for eval.\n",
    "        variable_averages = tf.train.ExponentialMovingAverage(\n",
    "            cifar10.MOVING_AVERAGE_DECAY)\n",
    "        variables_to_restore = variable_averages.variables_to_restore()\n",
    "        saver = tf.train.Saver(variables_to_restore)\n",
    "\n",
    "    # Build the summary operation based on the TF collection of Summaries.\n",
    "        summary_op = tf.summary.merge_all()\n",
    "\n",
    "        summary_writer = tf.summary.FileWriter(FLAGS.eval_dir, g)\n",
    "\n",
    "        while True:\n",
    "            eval_once(saver, summary_writer, top_k_op, summary_op)\n",
    "            if FLAGS.run_once:\n",
    "                break\n",
    "            time.sleep(FLAGS.eval_interval_secs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def main(argv=None):  # pylint: disable=unused-argument\n",
    "    \n",
    "    cifar10.maybe_download_and_extract()\n",
    "    if tf.gfile.Exists(FLAGS.eval_dir):\n",
    "        tf.gfile.DeleteRecursively(FLAGS.eval_dir)\n",
    "    tf.gfile.MakeDirs(FLAGS.eval_dir)\n",
    "    evaluate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[[252, 252, 252],\n",
      "        [252, 252, 252],\n",
      "        [252, 252, 252],\n",
      "        ..., \n",
      "        [252, 252, 252],\n",
      "        [252, 252, 252],\n",
      "        [252, 252, 252]],\n",
      "\n",
      "       [[252, 252, 252],\n",
      "        [252, 252, 252],\n",
      "        [252, 252, 252],\n",
      "        ..., \n",
      "        [252, 252, 252],\n",
      "        [252, 252, 252],\n",
      "        [252, 252, 252]],\n",
      "\n",
      "       [[252, 252, 252],\n",
      "        [252, 252, 252],\n",
      "        [252, 252, 252],\n",
      "        ..., \n",
      "        [252, 252, 252],\n",
      "        [252, 252, 252],\n",
      "        [252, 252, 252]],\n",
      "\n",
      "       ..., \n",
      "       [[251, 251, 251],\n",
      "        [251, 251, 251],\n",
      "        [251, 251, 251],\n",
      "        ..., \n",
      "        [251, 251, 251],\n",
      "        [251, 251, 251],\n",
      "        [251, 251, 251]],\n",
      "\n",
      "       [[251, 251, 251],\n",
      "        [251, 251, 251],\n",
      "        [251, 251, 251],\n",
      "        ..., \n",
      "        [251, 251, 251],\n",
      "        [251, 251, 251],\n",
      "        [251, 251, 251]],\n",
      "\n",
      "       [[251, 251, 251],\n",
      "        [251, 251, 251],\n",
      "        [251, 251, 251],\n",
      "        ..., \n",
      "        [251, 251, 251],\n",
      "        [251, 251, 251],\n",
      "        [251, 251, 251]]], dtype=uint8)]\n",
      "[[6]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Tried to convert 'input' to a tensor and failed. Error: Argument must be a dense tensor: [array([[[252, 252, 252],\n        [252, 252, 252],\n        [252, 252, 252],\n        ..., \n        [252, 252, 252],\n        [252, 252, 252],\n        [252, 252, 252]],\n\n       [[252, 252, 252],\n        [252, 252, 252],\n        [252, 252, 252],\n        ..., \n        [252, 252, 252],\n        [252, 252, 252],\n        [252, 252, 252]],\n\n       [[252, 252, 252],\n        [252, 252, 252],\n        [252, 252, 252],\n        ..., \n        [252, 252, 252],\n        [252, 252, 252],\n        [252, 252, 252]],\n\n       ..., \n       [[251, 251, 251],\n        [251, 251, 251],\n        [251, 251, 251],\n        ..., \n        [251, 251, 251],\n        [251, 251, 251],\n        [251, 251, 251]],\n\n       [[251, 251, 251],\n        [251, 251, 251],\n        [251, 251, 251],\n        ..., \n        [251, 251, 251],\n        [251, 251, 251],\n        [251, 251, 251]],\n\n       [[251, 251, 251],\n        [251, 251, 251],\n        [251, 251, 251],\n        ..., \n        [251, 251, 251],\n        [251, 251, 251],\n        [251, 251, 251]]], dtype=uint8)] - got shape [1, 349, 400, 3], but wanted [1].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\iFede94\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36mapply_op\u001b[1;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    490\u001b[0m                 \u001b[0mas_ref\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_arg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_ref\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 491\u001b[1;33m                 preferred_dtype=default_dtype)\n\u001b[0m\u001b[0;32m    492\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\iFede94\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36minternal_convert_to_tensor\u001b[1;34m(value, dtype, name, as_ref, preferred_dtype)\u001b[0m\n\u001b[0;32m    703\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 704\u001b[1;33m           \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    705\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\iFede94\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[1;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[0;32m    112\u001b[0m   \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\iFede94\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[1;34m(value, dtype, shape, name, verify_shape)\u001b[0m\n\u001b[0;32m    101\u001b[0m   tensor_value.tensor.CopyFrom(\n\u001b[1;32m--> 102\u001b[1;33m       tensor_util.make_tensor_proto(value, dtype=dtype, shape=shape, verify_shape=verify_shape))\n\u001b[0m\u001b[0;32m    103\u001b[0m   \u001b[0mdtype_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtensor_value\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\iFede94\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_util.py\u001b[0m in \u001b[0;36mmake_tensor_proto\u001b[1;34m(values, dtype, shape, verify_shape)\u001b[0m\n\u001b[0;32m    378\u001b[0m                              \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnparray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 379\u001b[1;33m                              _GetDenseDimensions(values)))\n\u001b[0m\u001b[0;32m    380\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Argument must be a dense tensor: [array([[[252, 252, 252],\n        [252, 252, 252],\n        [252, 252, 252],\n        ..., \n        [252, 252, 252],\n        [252, 252, 252],\n        [252, 252, 252]],\n\n       [[252, 252, 252],\n        [252, 252, 252],\n        [252, 252, 252],\n        ..., \n        [252, 252, 252],\n        [252, 252, 252],\n        [252, 252, 252]],\n\n       [[252, 252, 252],\n        [252, 252, 252],\n        [252, 252, 252],\n        ..., \n        [252, 252, 252],\n        [252, 252, 252],\n        [252, 252, 252]],\n\n       ..., \n       [[251, 251, 251],\n        [251, 251, 251],\n        [251, 251, 251],\n        ..., \n        [251, 251, 251],\n        [251, 251, 251],\n        [251, 251, 251]],\n\n       [[251, 251, 251],\n        [251, 251, 251],\n        [251, 251, 251],\n        ..., \n        [251, 251, 251],\n        [251, 251, 251],\n        [251, 251, 251]],\n\n       [[251, 251, 251],\n        [251, 251, 251],\n        [251, 251, 251],\n        ..., \n        [251, 251, 251],\n        [251, 251, 251],\n        [251, 251, 251]]], dtype=uint8)] - got shape [1, 349, 400, 3], but wanted [1].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\iFede94\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36mapply_op\u001b[1;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    504\u001b[0m               observed = ops.internal_convert_to_tensor(\n\u001b[1;32m--> 505\u001b[1;33m                   values, as_ref=input_arg.is_ref).dtype.name\n\u001b[0m\u001b[0;32m    506\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\iFede94\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36minternal_convert_to_tensor\u001b[1;34m(value, dtype, name, as_ref, preferred_dtype)\u001b[0m\n\u001b[0;32m    703\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 704\u001b[1;33m           \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    705\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\iFede94\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[1;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[0;32m    112\u001b[0m   \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\iFede94\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[1;34m(value, dtype, shape, name, verify_shape)\u001b[0m\n\u001b[0;32m    101\u001b[0m   tensor_value.tensor.CopyFrom(\n\u001b[1;32m--> 102\u001b[1;33m       tensor_util.make_tensor_proto(value, dtype=dtype, shape=shape, verify_shape=verify_shape))\n\u001b[0m\u001b[0;32m    103\u001b[0m   \u001b[0mdtype_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtensor_value\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\iFede94\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_util.py\u001b[0m in \u001b[0;36mmake_tensor_proto\u001b[1;34m(values, dtype, shape, verify_shape)\u001b[0m\n\u001b[0;32m    378\u001b[0m                              \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnparray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 379\u001b[1;33m                              _GetDenseDimensions(values)))\n\u001b[0m\u001b[0;32m    380\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Argument must be a dense tensor: [array([[[252, 252, 252],\n        [252, 252, 252],\n        [252, 252, 252],\n        ..., \n        [252, 252, 252],\n        [252, 252, 252],\n        [252, 252, 252]],\n\n       [[252, 252, 252],\n        [252, 252, 252],\n        [252, 252, 252],\n        ..., \n        [252, 252, 252],\n        [252, 252, 252],\n        [252, 252, 252]],\n\n       [[252, 252, 252],\n        [252, 252, 252],\n        [252, 252, 252],\n        ..., \n        [252, 252, 252],\n        [252, 252, 252],\n        [252, 252, 252]],\n\n       ..., \n       [[251, 251, 251],\n        [251, 251, 251],\n        [251, 251, 251],\n        ..., \n        [251, 251, 251],\n        [251, 251, 251],\n        [251, 251, 251]],\n\n       [[251, 251, 251],\n        [251, 251, 251],\n        [251, 251, 251],\n        ..., \n        [251, 251, 251],\n        [251, 251, 251],\n        [251, 251, 251]],\n\n       [[251, 251, 251],\n        [251, 251, 251],\n        [251, 251, 251],\n        ..., \n        [251, 251, 251],\n        [251, 251, 251],\n        [251, 251, 251]]], dtype=uint8)] - got shape [1, 349, 400, 3], but wanted [1].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-a2382b257a51>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\iFede94\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\platform\\app.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(main, argv)\u001b[0m\n\u001b[0;32m     46\u001b[0m   \u001b[1;31m# Call the main function, passing through any arguments\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m   \u001b[1;31m# to the final program.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m   \u001b[0m_sys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_sys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mflags_passthrough\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-1e5951b85b42>\u001b[0m in \u001b[0;36mmain\u001b[1;34m(argv)\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDeleteRecursively\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFLAGS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMakeDirs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFLAGS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-5-9322e62e0b4f>\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;31m# Build a Graph that computes the logits predictions from the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;31m# inference model.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0mlogits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcifar10\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minference\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;31m# Calculate predictions.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Utenti\\Federico\\Documenti\\Atom\\ProjUrMi\\ACA\\models-master\\tutorials\\image\\cifar10\\cifar10.py\u001b[0m in \u001b[0;36minference\u001b[1;34m(images)\u001b[0m\n\u001b[0;32m    206\u001b[0m                                          \u001b[0mstddev\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5e-2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m                                          wd=0.0)\n\u001b[1;32m--> 208\u001b[1;33m     \u001b[0mconv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'SAME'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m     \u001b[0mbiases\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_variable_on_cpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'biases'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant_initializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m     \u001b[0mpre_activation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias_add\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbiases\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\iFede94\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\u001b[0m in \u001b[0;36mconv2d\u001b[1;34m(input, filter, strides, padding, use_cudnn_on_gpu, data_format, name)\u001b[0m\n\u001b[0;32m    401\u001b[0m                                 \u001b[0mstrides\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstrides\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    402\u001b[0m                                 \u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 403\u001b[1;33m                                 data_format=data_format, name=name)\n\u001b[0m\u001b[0;32m    404\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    405\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\iFede94\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36mapply_op\u001b[1;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    507\u001b[0m               raise ValueError(\n\u001b[0;32m    508\u001b[0m                   \u001b[1;34m\"Tried to convert '%s' to a tensor and failed. Error: %s\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 509\u001b[1;33m                   (input_name, err))\n\u001b[0m\u001b[0;32m    510\u001b[0m             prefix = (\"Input '%s' of '%s' Op has type %s that does not match\" %\n\u001b[0;32m    511\u001b[0m                       (input_name, op_type_name, observed))\n",
      "\u001b[1;31mValueError\u001b[0m: Tried to convert 'input' to a tensor and failed. Error: Argument must be a dense tensor: [array([[[252, 252, 252],\n        [252, 252, 252],\n        [252, 252, 252],\n        ..., \n        [252, 252, 252],\n        [252, 252, 252],\n        [252, 252, 252]],\n\n       [[252, 252, 252],\n        [252, 252, 252],\n        [252, 252, 252],\n        ..., \n        [252, 252, 252],\n        [252, 252, 252],\n        [252, 252, 252]],\n\n       [[252, 252, 252],\n        [252, 252, 252],\n        [252, 252, 252],\n        ..., \n        [252, 252, 252],\n        [252, 252, 252],\n        [252, 252, 252]],\n\n       ..., \n       [[251, 251, 251],\n        [251, 251, 251],\n        [251, 251, 251],\n        ..., \n        [251, 251, 251],\n        [251, 251, 251],\n        [251, 251, 251]],\n\n       [[251, 251, 251],\n        [251, 251, 251],\n        [251, 251, 251],\n        ..., \n        [251, 251, 251],\n        [251, 251, 251],\n        [251, 251, 251]],\n\n       [[251, 251, 251],\n        [251, 251, 251],\n        [251, 251, 251],\n        ..., \n        [251, 251, 251],\n        [251, 251, 251],\n        [251, 251, 251]]], dtype=uint8)] - got shape [1, 349, 400, 3], but wanted [1]."
     ]
    }
   ],
   "source": [
    "\n",
    "tf.app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
