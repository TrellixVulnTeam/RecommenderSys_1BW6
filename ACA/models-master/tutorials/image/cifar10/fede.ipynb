{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Copyright 2015 The TensorFlow Authors. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ==============================================================================\n",
    "\n",
    "\"\"\"Evaluation for CIFAR-10.\n",
    "\n",
    "Accuracy:\n",
    "cifar10_train.py achieves 83.0% accuracy after 100K steps (256 epochs\n",
    "of data) as judged by cifar10_eval.py.\n",
    "\n",
    "Speed:\n",
    "On a single Tesla K40, cifar10_train.py processes a single batch of 128 images\n",
    "in 0.25-0.35 sec (i.e. 350 - 600 images /sec). The model reaches ~86%\n",
    "accuracy after 100K steps in 8 hours of training time.\n",
    "\n",
    "Usage:\n",
    "Please see the tutorial and website for how to download the CIFAR-10\n",
    "data set, compile the program and train the model.\n",
    "\n",
    "http://tensorflow.org/tutorials/deep_cnn/\n",
    "\"\"\"\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "from datetime import datetime\n",
    "import math\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "\n",
    "import cifar10\n",
    "import cifar10_input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "FLAGS = tf.app.flags.FLAGS\n",
    "\n",
    "tf.app.flags.DEFINE_string('eval_dir', '/tmp/cifar10_eval',\n",
    "                           \"\"\"Directory where to write event logs.\"\"\")\n",
    "tf.app.flags.DEFINE_string('eval_data', 'test',\n",
    "                           \"\"\"Either 'test' or 'train_eval'.\"\"\")\n",
    "tf.app.flags.DEFINE_string('checkpoint_dir', '/tmp/cifar10_train',\n",
    "                           \"\"\"Directory where to read model checkpoints.\"\"\")\n",
    "tf.app.flags.DEFINE_integer('eval_interval_secs', 60 * 5,\n",
    "                            \"\"\"How often to run the eval.\"\"\")\n",
    "tf.app.flags.DEFINE_integer('num_examples', 10000,\n",
    "                            \"\"\"Number of examples to run.\"\"\")\n",
    "tf.app.flags.DEFINE_boolean('run_once', False,\n",
    "                         \"\"\"Whether to run eval only once.\"\"\")\n",
    "\n",
    "IMAGE_SIZE = 24\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def eval_once(saver, summary_writer, top_k_op, summary_op):\n",
    "    \"\"\"Run Eval once.\n",
    "\n",
    "  Args:\n",
    "    saver: Saver.\n",
    "    summary_writer: Summary writer.\n",
    "    top_k_op: Top K op.\n",
    "    summary_op: Summary op.\n",
    "  \"\"\"\n",
    "    with tf.Session() as sess:\n",
    "        ckpt = tf.train.get_checkpoint_state(FLAGS.checkpoint_dir)\n",
    "        if ckpt and ckpt.model_checkpoint_path:\n",
    "        # Restores from checkpoint\n",
    "            saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "        # Assuming model_checkpoint_path looks something like:\n",
    "        #   /my-favorite-path/cifar10_train/model.ckpt-0,\n",
    "        # extract global_step from it.\n",
    "            global_step = ckpt.model_checkpoint_path.split('/')[-1].split('-')[-1]\n",
    "        else:\n",
    "            print('No checkpoint file found')\n",
    "            return\n",
    "\n",
    "    # Start the queue runners.\n",
    "        coord = tf.train.Coordinator()\n",
    "        try:\n",
    "            threads = []\n",
    "            for qr in tf.get_collection(tf.GraphKeys.QUEUE_RUNNERS):\n",
    "                threads.extend(qr.create_threads(sess, coord=coord, daemon=True,\n",
    "                                         start=True))\n",
    "\n",
    "            num_iter = int(math.ceil(FLAGS.num_examples / FLAGS.batch_size))\n",
    "            true_count = 0  # Counts the number of correct predictions.\n",
    "            total_sample_count = num_iter * FLAGS.batch_size\n",
    "            step = 0\n",
    "            while step < num_iter and not coord.should_stop():\n",
    "                predictions = sess.run([top_k_op])\n",
    "                true_count += np.sum(predictions)\n",
    "                step += 1\n",
    "\n",
    "        # Compute precision @ 1.\n",
    "            precision = true_count / total_sample_count\n",
    "            print('%s: precision @ 1 = %.3f' % (datetime.now(), precision))\n",
    "\n",
    "            summary = tf.Summary()\n",
    "            summary.ParseFromString(sess.run(summary_op))\n",
    "            summary.value.add(tag='Precision @ 1', simple_value=precision)\n",
    "            summary_writer.add_summary(summary, global_step)\n",
    "        except Exception as e:  # pylint: disable=broad-except\n",
    "            coord.request_stop(e)\n",
    "\n",
    "        coord.request_stop()\n",
    "        coord.join(threads, stop_grace_period_secs=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def inputs():\n",
    "    filename_queue = tf.train.string_input_producer(\n",
    "    tf.train.match_filenames_once(\"./images/6.jpg\"))\n",
    "\n",
    "    # Read an entire image file which is required since they're JPEGs, if the images\n",
    "    # are too large they could be split in advance to smaller files or use the Fixed\n",
    "    # reader to split up the file.\n",
    "    image_reader = tf.WholeFileReader()\n",
    "\n",
    "    # Read a whole file from the queue, the first returned value in the tuple is the\n",
    "    # filename which we are ignoring.\n",
    "    _,image_file = image_reader.read(filename_queue)\n",
    "\n",
    "    label = tf.Variable(6)\n",
    "    \n",
    "    # Decode the image as a JPEG file, this will turn it into a Tensor which we can\n",
    "    # then use in training.\n",
    "    image = tf.image.decode_jpeg(image_file)\n",
    "\n",
    "    # Start a new session to show example output.\n",
    "    with tf.Session() as sess:\n",
    "        # Required to get the filename matching to run.\n",
    "        init = (tf.global_variables_initializer(), tf.local_variables_initializer())\n",
    "        sess.run([init])\n",
    "\n",
    "        # Coordinate the loading of image files.\n",
    "        coord = tf.train.Coordinator()\n",
    "        threads = tf.train.start_queue_runners(coord=coord)\n",
    "        my_img = image.eval()\n",
    "        Image.fromarray(np.asarray(my_img)).show()\n",
    "        # Get an image tensor and print its value.\n",
    "        image_tensor = sess.run([image])\n",
    "        label_tensor = sess.run([label])\n",
    "        # Finish off the filename queue coordinator.\n",
    "        coord.request_stop()\n",
    "        coord.join(threads)\n",
    "        return image_tensor, label_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def modify_image(image):\n",
    "    reshaped_image = image\n",
    "\n",
    "    height = IMAGE_SIZE\n",
    "    width = IMAGE_SIZE\n",
    "\n",
    "  # Image processing for evaluation.\n",
    "  # Crop the central [height, width] of the image.\n",
    "    resized_image = tf.image.resize_image_with_crop_or_pad(reshaped_image,height, width)\n",
    "\n",
    "  # Subtract off the mean and divide by the variance of the pixels.\n",
    "    float_image = tf.image.per_image_standardization(resized_image)\n",
    "\n",
    "  # Set the shapes of tensors.\n",
    "    float_image.set_shape([height, width, 3])\n",
    "    return float_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def evaluate():\n",
    "    \"\"\"Eval CIFAR-10 for a number of steps.\"\"\"\n",
    "    with tf.Graph().as_default() as g:\n",
    "    # Get images and labels for CIFAR-10.\n",
    "        eval_data = FLAGS.eval_data == 'test'\n",
    "       # images, labels = cifar10.inputs(eval_data=eval_data)\n",
    "        image, label = inputs()\n",
    "        image2 = modify_image(image)\n",
    "        min_fraction_of_examples_in_queue = 0.4\n",
    "        num_examples_per_epoch = 10000\n",
    "        batch_size = 128\n",
    "        label2 = tf.convert_to_tensor(label_tensor)\n",
    "        min_queue_examples = int(num_examples_per_epoch * min_fraction_of_examples_in_queue)\n",
    "  # Generate a batch of images and labels by building up a queue of examples.\n",
    "\n",
    "        images, labels = cifar10_input._generate_image_and_label_batch(float_image, label2,\n",
    "                                         min_queue_examples, batch_size,\n",
    "                                         shuffle=False)\n",
    "    # Build a Graph that computes the logits predictions from the\n",
    "    # inference model.\n",
    "        logits = cifar10.inference(images)\n",
    "    \n",
    "    # Calculate predictions.\n",
    "        top_k_op = tf.nn.in_top_k(logits, labels, 1)\n",
    "\n",
    "    # Restore the moving average version of the learned variables for eval.\n",
    "        variable_averages = tf.train.ExponentialMovingAverage(\n",
    "            cifar10.MOVING_AVERAGE_DECAY)\n",
    "        variables_to_restore = variable_averages.variables_to_restore()\n",
    "        saver = tf.train.Saver(variables_to_restore)\n",
    "\n",
    "    # Build the summary operation based on the TF collection of Summaries.\n",
    "        summary_op = tf.summary.merge_all()\n",
    "\n",
    "        summary_writer = tf.summary.FileWriter(FLAGS.eval_dir, g)\n",
    "\n",
    "        while True:\n",
    "            eval_once(saver, summary_writer, top_k_op, summary_op)\n",
    "            if FLAGS.run_once:\n",
    "                break\n",
    "            time.sleep(FLAGS.eval_interval_secs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def main(argv=None):  # pylint: disable=unused-argument\n",
    "    \n",
    "    cifar10.maybe_download_and_extract()\n",
    "    if tf.gfile.Exists(FLAGS.eval_dir):\n",
    "        tf.gfile.DeleteRecursively(FLAGS.eval_dir)\n",
    "    tf.gfile.MakeDirs(FLAGS.eval_dir)\n",
    "    evaluate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Argument must be a dense tensor: [array([[[252, 252, 252],\n        [252, 252, 252],\n        [252, 252, 252],\n        ..., \n        [252, 252, 252],\n        [252, 252, 252],\n        [252, 252, 252]],\n\n       [[252, 252, 252],\n        [252, 252, 252],\n        [252, 252, 252],\n        ..., \n        [252, 252, 252],\n        [252, 252, 252],\n        [252, 252, 252]],\n\n       [[252, 252, 252],\n        [252, 252, 252],\n        [252, 252, 252],\n        ..., \n        [252, 252, 252],\n        [252, 252, 252],\n        [252, 252, 252]],\n\n       ..., \n       [[251, 251, 251],\n        [251, 251, 251],\n        [251, 251, 251],\n        ..., \n        [251, 251, 251],\n        [251, 251, 251],\n        [251, 251, 251]],\n\n       [[251, 251, 251],\n        [251, 251, 251],\n        [251, 251, 251],\n        ..., \n        [251, 251, 251],\n        [251, 251, 251],\n        [251, 251, 251]],\n\n       [[251, 251, 251],\n        [251, 251, 251],\n        [251, 251, 251],\n        ..., \n        [251, 251, 251],\n        [251, 251, 251],\n        [251, 251, 251]]], dtype=uint8)] - got shape [1, 349, 400, 3], but wanted [1].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-a2382b257a51>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\iFede94\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\platform\\app.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(main, argv)\u001b[0m\n\u001b[0;32m     46\u001b[0m   \u001b[1;31m# Call the main function, passing through any arguments\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m   \u001b[1;31m# to the final program.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m   \u001b[0m_sys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_sys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mflags_passthrough\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-1e5951b85b42>\u001b[0m in \u001b[0;36mmain\u001b[1;34m(argv)\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDeleteRecursively\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFLAGS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMakeDirs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFLAGS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-6-27e9e6b084f3>\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m        \u001b[1;31m# images, labels = cifar10.inputs(eval_data=eval_data)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[0mimage2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodify_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m         \u001b[0mmin_fraction_of_examples_in_queue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.4\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mnum_examples_per_epoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10000\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-93e35f9c593b>\u001b[0m in \u001b[0;36mmodify_image\u001b[1;34m(image)\u001b[0m\n\u001b[0;32m      7\u001b[0m   \u001b[1;31m# Image processing for evaluation.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m   \u001b[1;31m# Crop the central [height, width] of the image.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mresized_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize_image_with_crop_or_pad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreshaped_image\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mheight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m   \u001b[1;31m# Subtract off the mean and divide by the variance of the pixels.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\iFede94\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\image_ops_impl.py\u001b[0m in \u001b[0;36mresize_image_with_crop_or_pad\u001b[1;34m(image, target_height, target_width)\u001b[0m\n\u001b[0;32m    589\u001b[0m     \u001b[0;31m`\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnew_height\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_width\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchannels\u001b[0m\u001b[1;33m]\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m   \"\"\"\n\u001b[1;32m--> 591\u001b[1;33m   \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'image'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    592\u001b[0m   \u001b[0mimage_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m   \u001b[0mis_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\iFede94\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[1;34m(value, dtype, name, preferred_dtype)\u001b[0m\n\u001b[0;32m    637\u001b[0m       \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    638\u001b[0m       \u001b[0mpreferred_dtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpreferred_dtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 639\u001b[1;33m       as_ref=False)\n\u001b[0m\u001b[0;32m    640\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\iFede94\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36minternal_convert_to_tensor\u001b[1;34m(value, dtype, name, as_ref, preferred_dtype)\u001b[0m\n\u001b[0;32m    702\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    703\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 704\u001b[1;33m           \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    705\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    706\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\iFede94\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[1;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[0;32m    111\u001b[0m                                          as_ref=False):\n\u001b[0;32m    112\u001b[0m   \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\iFede94\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[1;34m(value, dtype, shape, name, verify_shape)\u001b[0m\n\u001b[0;32m    100\u001b[0m   \u001b[0mtensor_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m   tensor_value.tensor.CopyFrom(\n\u001b[1;32m--> 102\u001b[1;33m       tensor_util.make_tensor_proto(value, dtype=dtype, shape=shape, verify_shape=verify_shape))\n\u001b[0m\u001b[0;32m    103\u001b[0m   \u001b[0mdtype_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtensor_value\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m   const_tensor = g.create_op(\n",
      "\u001b[1;32mC:\\Users\\iFede94\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_util.py\u001b[0m in \u001b[0;36mmake_tensor_proto\u001b[1;34m(values, dtype, shape, verify_shape)\u001b[0m\n\u001b[0;32m    377\u001b[0m                          \"\"\" - got shape %s, but wanted %s.\"\"\" % (\n\u001b[0;32m    378\u001b[0m                              \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnparray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 379\u001b[1;33m                              _GetDenseDimensions(values)))\n\u001b[0m\u001b[0;32m    380\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    381\u001b[0m     \u001b[1;31m# python/numpy default float type is float64. We prefer float32 instead.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Argument must be a dense tensor: [array([[[252, 252, 252],\n        [252, 252, 252],\n        [252, 252, 252],\n        ..., \n        [252, 252, 252],\n        [252, 252, 252],\n        [252, 252, 252]],\n\n       [[252, 252, 252],\n        [252, 252, 252],\n        [252, 252, 252],\n        ..., \n        [252, 252, 252],\n        [252, 252, 252],\n        [252, 252, 252]],\n\n       [[252, 252, 252],\n        [252, 252, 252],\n        [252, 252, 252],\n        ..., \n        [252, 252, 252],\n        [252, 252, 252],\n        [252, 252, 252]],\n\n       ..., \n       [[251, 251, 251],\n        [251, 251, 251],\n        [251, 251, 251],\n        ..., \n        [251, 251, 251],\n        [251, 251, 251],\n        [251, 251, 251]],\n\n       [[251, 251, 251],\n        [251, 251, 251],\n        [251, 251, 251],\n        ..., \n        [251, 251, 251],\n        [251, 251, 251],\n        [251, 251, 251]],\n\n       [[251, 251, 251],\n        [251, 251, 251],\n        [251, 251, 251],\n        ..., \n        [251, 251, 251],\n        [251, 251, 251],\n        [251, 251, 251]]], dtype=uint8)] - got shape [1, 349, 400, 3], but wanted [1]."
     ]
    }
   ],
   "source": [
    "\n",
    "tf.app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
